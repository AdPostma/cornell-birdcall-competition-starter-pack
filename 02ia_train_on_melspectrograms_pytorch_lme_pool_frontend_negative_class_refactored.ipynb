{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdcall.data import *\n",
    "from birdcall.metrics import *\n",
    "from birdcall.ops import *\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = pd.read_pickle('data/splits.pkl')\n",
    "positive_class_items = pd.read_pickle('data/positive_class_items.pkl')\n",
    "negative_class_items = pd.read_pickle('data/negative_class_items.pkl')\n",
    "north_american_birds_common = pd.read_pickle('data/north_american_birds_common.pkl')\n",
    "all_classes = pd.read_pickle('data/classes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export data\n",
    "from collections import defaultdict\n",
    "\n",
    "def translate_class(items, old_vocab, new_vocab):\n",
    "    items_with_translated_class = []\n",
    "    for cls_idx, path, duration in items:\n",
    "        items_with_translated_class.append((new_vocab.index(old_vocab[cls_idx]), path, duration))\n",
    "    return items_with_translated_class\n",
    "\n",
    "class MelspecPoolDatasetNegativeClass(torch.utils.data.Dataset):\n",
    "    def __init__(self, items, items_neg_class, north_american_birds_common, len_mult=20, specs_per_example=30, reshape_to_3ch=True, spec_dur=1.66):\n",
    "        self.cls_idx_to_recs = defaultdict(list)\n",
    "        for item in items:\n",
    "            self.cls_idx_to_recs[item[0]].append(item)\n",
    "        self.items = items\n",
    "        self.items_neg_class = items_neg_class\n",
    "        self.all_classes = classes\n",
    "        self.vocab = north_american_birds_common\n",
    "        self.specs_per_example = specs_per_example\n",
    "        self.len_mult = len_mult\n",
    "        self.reshape_to_3ch = reshape_to_3ch\n",
    "        self.spec_dur = spec_dur\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if np.random.rand() > 0.54:\n",
    "            cls_idx = idx % len(self.vocab)\n",
    "            recs = self.cls_idx_to_recs[cls_idx]\n",
    "            _, path, duration = recs[np.random.randint(0, len(recs))]\n",
    "        else:\n",
    "            cls_idx = -1\n",
    "            _, path, duration = self.items_neg_class[np.random.randint(len(self.items_neg_class))]\n",
    "            \n",
    "        example = self.sample_specs(path, duration, self.specs_per_example)\n",
    "        if self.reshape_to_3ch: example = example.reshape(-1, 3, 80, 212)\n",
    "        return example.astype(np.float32), self.one_hot_encode(cls_idx)\n",
    "    \n",
    "    def sample_specs(self, path, duration, count):\n",
    "        x, _ = sf.read(path)\n",
    "\n",
    "        if x.shape[0] < self.spec_dur*SAMPLE_RATE:\n",
    "            x =  np.tile(x, int(self.spec_dur*SAMPLE_RATE) // x.shape[0] + 1 ) # the shortest rec in the train set is 0.39 sec\n",
    "\n",
    "        xs = []\n",
    "        for _ in range(count):\n",
    "            start_frame = int(np.random.rand() * (x.shape[0] - self.spec_dur * SAMPLE_RATE))\n",
    "            xs.append(x[start_frame:start_frame+int(self.spec_dur*SAMPLE_RATE)])\n",
    "\n",
    "        specs = []\n",
    "        for x in xs:\n",
    "            specs.append(audio_to_melspec(x))\n",
    "        return np.stack(specs)\n",
    "    \n",
    "    def show(self, idx):\n",
    "        x = self[idx][0][0]\n",
    "        return plt.imshow(x.transpose(1,2,0)[:, :, 0])\n",
    "        \n",
    "    def one_hot_encode(self, y):\n",
    "        one_hot = np.zeros((len(self.vocab)))\n",
    "        if y != -1:\n",
    "            one_hot[y] = 1\n",
    "        return one_hot\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len_mult * len(self.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_items = np.array(positive_class_items)[splits[0][0]].tolist()\n",
    "val_items = np.array(positive_class_items)[splits[0][1]].tolist()\n",
    "negative_class_items = [(-1, item[1], item[2]) for item in negative_class_items]\n",
    "\n",
    "train_items = translate_class(train_items, all_classes, north_american_birds_common)\n",
    "val_items = translate_class(val_items, all_classes, north_american_birds_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_pickle('data/classes.pkl')\n",
    "north_american_birds_common = pd.read_pickle('data/north_american_birds_common.pkl')\n",
    "\n",
    "train_ds = MelspecPoolDatasetNegativeClass(train_items, negative_class_items, north_american_birds_common, len_mult=300)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, num_workers=NUM_WORKERS, pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export data\n",
    "class MelspecShortishValidatioDatasetNegativeClass(torch.utils.data.Dataset):\n",
    "    def __init__(self, items, vocab, negative_class_items=[], reshape_to_3ch=True):\n",
    "        self.vocab = vocab\n",
    "        self.items = items + negative_class_items\n",
    "        self.reshape_to_3ch = reshape_to_3ch\n",
    "        \n",
    "    def __len__(self): return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.items[idx]\n",
    "        \n",
    "        return self.create_example(self.items[idx])\n",
    "        \n",
    "    def create_example(self, item):\n",
    "        cls_idx, path, num_specs = item\n",
    "        \n",
    "        x, _ = sf.read(path)\n",
    "\n",
    "        example_duration = num_specs * 5 * SAMPLE_RATE\n",
    "        if x.shape[0] < example_duration:\n",
    "            x = np.tile(x, example_duration // x.shape[0] + 1)\n",
    "            \n",
    "        start_frame = 0\n",
    "        x = x[start_frame:example_duration]\n",
    "\n",
    "        xs = []\n",
    "        for i in range(num_specs):\n",
    "            for j in range(3):\n",
    "                start_frame = int((i * 3 + j) * 1.66 * SAMPLE_RATE)\n",
    "                xs.append(x[start_frame:start_frame+int(1.66*SAMPLE_RATE)])\n",
    "\n",
    "        specs = []\n",
    "        for x in xs:\n",
    "            specs.append(audio_to_melspec(x))\n",
    "        specs = np.stack(specs)\n",
    "        if self.reshape_to_3ch: specs = specs.reshape(-1, 3, 80, 212)\n",
    "\n",
    "        one_hot = np.zeros((len(self.vocab)))\n",
    "        if cls_idx != -1: one_hot[cls_idx] = 1\n",
    "\n",
    "        return specs.astype(np.float32), one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export data\n",
    "def bin_items_negative_class(items):        \n",
    "    binned_items = defaultdict(list)\n",
    "    for cls_idx, path, duration in items:\n",
    "        if duration < 7.5: binned_items[1].append((cls_idx, path, 1))\n",
    "        elif duration < 12.5: binned_items[2].append((cls_idx, path, 2))\n",
    "        elif duration < 25: binned_items[4].append((cls_idx, path, 4))\n",
    "        elif duration < 45: binned_items[6].append((cls_idx, path, 6))\n",
    "        else: binned_items[10].append((cls_idx, path, 10))\n",
    "    return binned_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_items_binned = bin_items_negative_class(val_items)\n",
    "\n",
    "np.random.shuffle(negative_class_items)\n",
    "negative_class_items = negative_class_items[:2500]\n",
    "negative_class_items_binned = bin_items_negative_class(negative_class_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrontEnd(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(80, affine=False)\n",
    "        self.register_parameter('alpha', torch.nn.Parameter(torch.tensor(0.)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, im_num, ch, y_dim, x_dim = x.shape\n",
    "        x = x ** torch.sigmoid(self.alpha)\n",
    "        x = x.view(-1, y_dim, x_dim)\n",
    "        x = self.bn(x)\n",
    "        return x.view(bs, im_num, ch, y_dim, x_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.frontend = FrontEnd()\n",
    "        self.cnn = nn.Sequential(*list(torchvision.models.resnet34(True).children())[:-2])\n",
    "        self.classifier = nn.Sequential(*[\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, len(north_american_birds_common))\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs, im_num, ch, y_dim, x_dim = x.shape\n",
    "        x = self.frontend(x)\n",
    "        x = self.cnn(x.view(-1, ch, y_dim, x_dim))\n",
    "        x = x.mean((2,3))\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(bs, im_num, -1)\n",
    "        x = lme_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "for epoch in range(130):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        model.train()\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if np.isnan(loss.item()): \n",
    "            print(f'!!! nan encountered in loss !!! alpha: epoch: {epoch}\\n')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "    if epoch % 5 == 4:\n",
    "        model.eval();\n",
    "        preds = []\n",
    "        targs = []\n",
    "\n",
    "        for num_specs in val_items_binned.keys():\n",
    "            valid_ds = MelspecShortishValidatioDataset(val_items_binned[num_specs], north_american_birds_common, negative_class_items_binned[num_specs])\n",
    "            valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=2*16, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data in valid_dl:\n",
    "                    inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                    outputs = model(inputs)\n",
    "                    preds.append(outputs.cpu().detach())\n",
    "                    targs.append(labels.cpu().detach())\n",
    "\n",
    "        preds = torch.cat(preds)\n",
    "        targs = torch.cat(targs)\n",
    "\n",
    "        accuracy = accuracy_score(preds.sigmoid() > 0.5, targs)\n",
    "        f1 = f1_score(preds.sigmoid() > 0.5, targs, average='micro')\n",
    "        print(f'[{epoch + 1}, {(time.time() - t0)/60:.1f}] loss: {running_loss / (len(train_dl)-1):.3f}, acc: {accuracy:.3f}, f1: {f1:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "        torch.save(model.state_dict(), f'models/{epoch+1}_lmepool_frontend_neg_class_refactored_{round(f1, 2)}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = []\n",
    "ts = []\n",
    "for t in np.linspace(0.4, 1, 61):\n",
    "    f1s.append(f1_score(preds.sigmoid() > t, targs, average='micro'))\n",
    "    ts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(f1s), accuracy_score(preds.sigmoid() > ts[np.argmax(f1s)], targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[np.argmax(f1s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdcall.metrics import *\n",
    "\n",
    "preds_to_tp_fp_fn(preds, targs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
