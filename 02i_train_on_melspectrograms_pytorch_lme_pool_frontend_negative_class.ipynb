{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdcall.data import *\n",
    "from birdcall.metrics import *\n",
    "from birdcall.ops import *\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_pickle('data/classes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "north_american_birds = train[train.country.isin(['United States', 'Canada', 'Mexico'])].ebird_code.value_counts()\n",
    "north_american_birds_common = north_american_birds[north_american_birds == 100].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daejun',\n",
       " 'houfin',\n",
       " 'cacwre',\n",
       " 'blujay',\n",
       " 'marwre',\n",
       " 'astfly',\n",
       " 'purfin',\n",
       " 'spotow',\n",
       " 'pasfly',\n",
       " 'warvir',\n",
       " 'foxspa',\n",
       " 'comgra',\n",
       " 'ruckin',\n",
       " 'mouchi',\n",
       " 'whtspa',\n",
       " 'eastow',\n",
       " 'bushti',\n",
       " 'whcspa',\n",
       " 'gnttow',\n",
       " 'dowwoo',\n",
       " 'wesmea',\n",
       " 'rebwoo',\n",
       " 'sonspa',\n",
       " 'carwre',\n",
       " 'brdowl',\n",
       " 'evegro',\n",
       " 'bnhcow',\n",
       " 'fiespa',\n",
       " 'indbun',\n",
       " 'swaspa',\n",
       " 'bulori',\n",
       " 'rebnut',\n",
       " 'whbnut',\n",
       " 'amecro',\n",
       " 'annhum',\n",
       " 'rewbla',\n",
       " 'herthr',\n",
       " 'bkhgro',\n",
       " 'bkcchi',\n",
       " 'orcwar',\n",
       " 'linspa',\n",
       " 'amegfi',\n",
       " 'vesspa',\n",
       " 'logshr',\n",
       " 'buggna',\n",
       " 'tuftit',\n",
       " 'gockin',\n",
       " 'savspa',\n",
       " 'bewwre',\n",
       " 'pilwoo',\n",
       " 'canwre',\n",
       " 'norcar',\n",
       " 'scoori',\n",
       " 'brespa',\n",
       " 'comyel',\n",
       " 'amerob',\n",
       " 'pinsis']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "north_american_birds_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_class_items  = []\n",
    "\n",
    "for ebird in north_american_birds_common:\n",
    "    paths = list(Path(f'data/train_resampled/{ebird}').iterdir())\n",
    "    for path in paths:\n",
    "        positive_class_items.append((classes.index(ebird), path, sf.info(path).duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_class_items = []\n",
    "\n",
    "for directory in Path(f'data/train_resampled/').iterdir():\n",
    "    if directory.name not in north_american_birds_common:\n",
    "        for path in directory.iterdir():\n",
    "            negative_class_items.append((classes.index(directory.name), path, sf.info(path).duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(positive_class_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(positive_class_items, 'data/positive_class_items.pkl')\n",
    "pd.to_pickle(negative_class_items, 'data/negative_class_items.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = StratifiedKFold()\n",
    "splits = list(sk.split([item[0] for item in positive_class_items], [item[0] for item in positive_class_items]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(splits, 'data/splits.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4560,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(north_american_birds_common, 'data/north_american_birds_common.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(north_american_birds_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = pd.read_pickle('data/splits.pkl')\n",
    "positive_class_items = pd.read_pickle('data/positive_class_items.pkl')\n",
    "negative_class_items = pd.read_pickle('data/negative_class_items.pkl')\n",
    "north_american_birds_common = pd.read_pickle('data/north_american_birds_common.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class MelspecPoolDatasetNegativeClass(torch.utils.data.Dataset):\n",
    "    def __init__(self, items, items_neg_class, classes, north_american_birds_common, len_mult=20, specs_per_example=30):\n",
    "        self.recs = defaultdict(list)\n",
    "        for item in items:\n",
    "            self.recs[item[0]].append(item)\n",
    "        self.items = items\n",
    "        self.items_neg_class = items_neg_class\n",
    "        self.all_classes = classes\n",
    "        self.vocab = north_american_birds_common\n",
    "        self.specs_per_example = specs_per_example\n",
    "        self.len_mult = len_mult\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if np.random.rand() > 0.56:\n",
    "            cls_idx = idx % len(self.vocab)\n",
    "            ebird_idx = self.all_classes.index(self.vocab[cls_idx])\n",
    "            recs = self.recs[ebird_idx]\n",
    "            _, path, duration = recs[np.random.randint(0, len(recs))]\n",
    "        else:\n",
    "            cls_idx = -1\n",
    "            _, path, duration = self.items_neg_class[np.random.randint(len(self.items_neg_class))]\n",
    "            \n",
    "        example = self.sample_specs(path, duration, self.specs_per_example)\n",
    "        imgs = example.reshape(-1, 3, 80, 212)\n",
    "        return imgs.astype(np.float32), self.one_hot_encode(cls_idx)\n",
    "    \n",
    "    def sample_specs(self, path, duration, count):\n",
    "        x, _ = sf.read(path)\n",
    "\n",
    "        if x.shape[0] < 1.66*SAMPLE_RATE:\n",
    "            x =  np.tile(x, 5) # the shortest rec in the train set is 0.39 sec\n",
    "\n",
    "        xs = []\n",
    "        for _ in range(count):\n",
    "            start_frame = int(np.random.rand() * (x.shape[0] - 1.66 * SAMPLE_RATE))\n",
    "            xs.append(x[start_frame:start_frame+int(1.66*SAMPLE_RATE)])\n",
    "\n",
    "        specs = []\n",
    "        for x in xs:\n",
    "            specs.append(audio_to_melspec(x))\n",
    "        return np.stack(specs)\n",
    "    \n",
    "    def show(self, idx):\n",
    "        x = self[idx][0][0]\n",
    "        return plt.imshow(x.transpose(1,2,0)[:, :, 0])\n",
    "        \n",
    "    def one_hot_encode(self, y):\n",
    "        one_hot = np.zeros((len(self.vocab)))\n",
    "        if y != -1:\n",
    "            one_hot[y] = 1\n",
    "        return one_hot\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len_mult * len(self.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_items = np.array(positive_class_items)[splits[0][0]].tolist()\n",
    "val_items = np.array(positive_class_items)[splits[0][1]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_pickle('data/classes.pkl')\n",
    "north_american_birds_common = pd.read_pickle('data/north_american_birds_common.pkl')\n",
    "\n",
    "train_ds = MelspecPoolDatasetNegativeClass(train_items, negative_class_items, classes, north_american_birds_common, len_mult=300)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, num_workers=NUM_WORKERS, pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelspecShortishValidatioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, items, vocab, items_neg_class):\n",
    "        self.vocab = vocab\n",
    "        self.items = items\n",
    "        self.items_neg_class = items_neg_class\n",
    "        \n",
    "    def __len__(self): return 2*len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.items):\n",
    "            return self.create_example(self.items[idx])\n",
    "        else:\n",
    "            return self.create_example(self.items_neg_class[np.random.randint(len(self.items_neg_class))], True)\n",
    "    \n",
    "    def create_example(self, item, neg_class=False):\n",
    "        cls_idx, path, num_specs = item\n",
    "        if neg_class: cls_idx = -1\n",
    "        \n",
    "        x, _ = sf.read(path)\n",
    "\n",
    "        example_duration = num_specs * 5 * SAMPLE_RATE\n",
    "        if x.shape[0] < example_duration:\n",
    "            x = np.tile(x, example_duration // x.shape[0] + 1)\n",
    "            \n",
    "        start_frame = 0\n",
    "        x = x[start_frame:example_duration]\n",
    "\n",
    "        xs = []\n",
    "        for i in range(num_specs):\n",
    "            for j in range(3):\n",
    "                start_frame = int((i * 3 + j) * 1.66 * SAMPLE_RATE)\n",
    "                xs.append(x[start_frame:start_frame+int(1.66*SAMPLE_RATE)])\n",
    "\n",
    "        specs = []\n",
    "        for x in xs:\n",
    "            specs.append(audio_to_melspec(x))\n",
    "        specs = np.stack(specs)\n",
    "        imgs = specs.reshape(-1, 3, 80, 212)\n",
    "\n",
    "        one_hot = np.zeros((len(self.vocab)))\n",
    "        if cls_idx != -1: one_hot[cls_idx] = 1\n",
    "\n",
    "        return imgs.astype(np.float32), one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_items_negative_class(items, vocab, all_classes):\n",
    "    val_recs = defaultdict(list)\n",
    "    for item in val_items:\n",
    "        val_recs[item[0]].append(item)\n",
    "        \n",
    "    binned_items = defaultdict(list)\n",
    "    for key in val_recs.keys():\n",
    "        cls_idx = vocab.index(all_classes[key])\n",
    "        for _, path, duration in val_recs[key]:\n",
    "            if duration < 7.5: binned_items[1].append((cls_idx, path, 1))\n",
    "            elif duration < 12.5: binned_items[2].append((cls_idx, path, 2))\n",
    "            elif duration < 25: binned_items[4].append((cls_idx, path, 4))\n",
    "            elif duration < 45: binned_items[6].append((cls_idx, path, 6))\n",
    "            else: binned_items[10].append((cls_idx, path, 10))\n",
    "    return binned_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_items_binned = bin_items_negative_class(val_items, north_american_birds_common, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_class_items_num_specs = defaultdict(list)\n",
    "for _, path, duration in negative_class_items:\n",
    "    if duration < 7.5: bin_num = 1\n",
    "    elif duration < 12.5: bin_num = 2\n",
    "    elif duration < 25: bin_num = 4\n",
    "    elif duration < 45: bin_num = 6\n",
    "    else: bin_num = 10\n",
    "    negative_class_items_num_specs[bin_num].append((1000, path, bin_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrontEnd(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(80, affine=False)\n",
    "        self.register_parameter('alpha', torch.nn.Parameter(torch.tensor(0.)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, im_num, ch, y_dim, x_dim = x.shape\n",
    "        x = x ** torch.sigmoid(self.alpha)\n",
    "        x = x.view(-1, y_dim, x_dim)\n",
    "        x = self.bn(x)\n",
    "        return x.view(bs, im_num, ch, y_dim, x_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.frontend = FrontEnd()\n",
    "        self.cnn = nn.Sequential(*list(torchvision.models.resnet34(True).children())[:-2])\n",
    "        self.classifier = nn.Sequential(*[\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, len(north_american_birds_common))\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs, im_num, ch, y_dim, x_dim = x.shape\n",
    "        x = self.frontend(x)\n",
    "        x = self.cnn(x.view(-1, ch, y_dim, x_dim))\n",
    "        x = x.mean((2,3))\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(bs, im_num, -1)\n",
    "        x = lme_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('models/130_lmepool_frontend_0.72.pth')\n",
    "\n",
    "del state_dict['classifier.8.weight']\n",
    "del state_dict['classifier.8.bias']\n",
    "\n",
    "model.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 20.0] loss: 0.005, acc: 0.775, f1: 0.753\n",
      "[10, 39.9] loss: 0.003, acc: 0.782, f1: 0.768\n",
      "[15, 59.9] loss: 0.002, acc: 0.825, f1: 0.805\n",
      "[20, 79.9] loss: 0.002, acc: 0.776, f1: 0.759\n",
      "[25, 99.9] loss: 0.001, acc: 0.783, f1: 0.764\n",
      "[30, 119.9] loss: 0.001, acc: 0.811, f1: 0.785\n",
      "[35, 139.9] loss: 0.001, acc: 0.809, f1: 0.788\n",
      "[40, 159.9] loss: 0.001, acc: 0.769, f1: 0.740\n",
      "[45, 179.9] loss: 0.001, acc: 0.784, f1: 0.769\n",
      "[50, 199.9] loss: 0.001, acc: 0.788, f1: 0.774\n",
      "[55, 219.8] loss: 0.001, acc: 0.800, f1: 0.774\n",
      "[60, 239.8] loss: 0.002, acc: 0.823, f1: 0.795\n",
      "[65, 259.8] loss: 0.001, acc: 0.796, f1: 0.768\n",
      "[70, 279.8] loss: 0.001, acc: 0.755, f1: 0.744\n",
      "[75, 299.8] loss: 0.001, acc: 0.786, f1: 0.762\n",
      "[80, 319.7] loss: 0.001, acc: 0.763, f1: 0.747\n",
      "[85, 339.7] loss: 0.001, acc: 0.809, f1: 0.781\n",
      "[90, 359.6] loss: 0.001, acc: 0.779, f1: 0.756\n",
      "[95, 379.6] loss: 0.001, acc: 0.756, f1: 0.737\n",
      "[100, 399.5] loss: 0.001, acc: 0.785, f1: 0.761\n",
      "[105, 419.5] loss: 0.001, acc: 0.785, f1: 0.767\n",
      "[110, 439.5] loss: 0.001, acc: 0.770, f1: 0.753\n",
      "[115, 459.4] loss: 0.001, acc: 0.754, f1: 0.732\n",
      "[120, 479.4] loss: 0.001, acc: 0.797, f1: 0.762\n",
      "[125, 499.3] loss: 0.001, acc: 0.778, f1: 0.743\n",
      "[130, 519.3] loss: 0.001, acc: 0.768, f1: 0.751\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for epoch in range(130):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        model.train()\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if np.isnan(loss.item()): \n",
    "            print(f'!!! nan encountered in loss !!! alpha: epoch: {epoch}\\n')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "    if epoch % 5 == 4:\n",
    "        model.eval();\n",
    "        preds = []\n",
    "        targs = []\n",
    "        fns = []\n",
    "\n",
    "        for num_specs in val_items_binned.keys():\n",
    "            valid_ds = MelspecShortishValidatioDataset(val_items_binned[num_specs], north_american_birds_common, negative_class_items_num_specs[num_specs])\n",
    "            valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=2*16, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "            fns += [item[1].name for item in valid_ds.items]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data in valid_dl:\n",
    "                    inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                    outputs = model(inputs)\n",
    "                    preds.append(outputs.cpu().detach())\n",
    "                    targs.append(labels.cpu().detach())\n",
    "\n",
    "        preds = torch.cat(preds)\n",
    "        targs = torch.cat(targs)\n",
    "\n",
    "        accuracy = accuracy_score(preds.sigmoid() > 0.5, targs)\n",
    "        f1 = f1_score(preds.sigmoid() > 0.5, targs, average='micro')\n",
    "        print(f'[{epoch + 1}, {(time.time() - t0)/60:.1f}] loss: {running_loss / (len(train_dl)-1):.3f}, acc: {accuracy:.3f}, f1: {f1:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "        torch.save(model.state_dict(), f'models/{epoch+1}_lmepool_frontend_neg_class_{round(f1, 2)}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = []\n",
    "ts = []\n",
    "for t in np.linspace(0.4, 1, 61):\n",
    "    f1s.append(f1_score(preds.sigmoid() > t, targs, average='micro'))\n",
    "    ts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.767713004484305, 0.7956140350877193)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1s), accuracy_score(preds.sigmoid() > ts[np.argmax(f1s)], targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[np.argmax(f1s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(872), tensor(286), tensor(268))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from birdcall.metrics import *\n",
    "\n",
    "preds_to_tp_fp_fn(preds, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135, 19.9] loss: 0.001, acc: 0.795, f1: 0.762\n",
      "[140, 39.9] loss: 0.001, acc: 0.793, f1: 0.765\n",
      "[145, 59.8] loss: 0.001, acc: 0.782, f1: 0.752\n",
      "[150, 79.8] loss: 0.001, acc: 0.777, f1: 0.762\n",
      "[155, 99.7] loss: 0.001, acc: 0.774, f1: 0.745\n",
      "[160, 119.7] loss: 0.000, acc: 0.733, f1: 0.722\n",
      "[165, 139.6] loss: 0.001, acc: 0.762, f1: 0.751\n",
      "[170, 159.6] loss: 0.000, acc: 0.795, f1: 0.768\n",
      "[175, 179.5] loss: 0.001, acc: 0.793, f1: 0.775\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-33d46b06f472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'!!! nan encountered in loss !!! alpha: epoch: {epoch}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for epoch in range(130, 260):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        model.train()\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if np.isnan(loss.item()): \n",
    "            print(f'!!! nan encountered in loss !!! alpha: epoch: {epoch}\\n')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "    if epoch % 5 == 4:\n",
    "        model.eval();\n",
    "        preds = []\n",
    "        targs = []\n",
    "        fns = []\n",
    "\n",
    "        for num_specs in val_items_binned.keys():\n",
    "            valid_ds = MelspecShortishValidatioDataset(val_items_binned[num_specs], north_american_birds_common, negative_class_items_num_specs[num_specs])\n",
    "            valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=2*16, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "            fns += [item[1].name for item in valid_ds.items]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data in valid_dl:\n",
    "                    inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                    outputs = model(inputs)\n",
    "                    preds.append(outputs.cpu().detach())\n",
    "                    targs.append(labels.cpu().detach())\n",
    "\n",
    "        preds = torch.cat(preds)\n",
    "        targs = torch.cat(targs)\n",
    "\n",
    "        accuracy = accuracy_score(preds.sigmoid() > 0.5, targs)\n",
    "        f1 = f1_score(preds.sigmoid() > 0.5, targs, average='micro')\n",
    "        print(f'[{epoch + 1}, {(time.time() - t0)/60:.1f}] loss: {running_loss / (len(train_dl)-1):.3f}, acc: {accuracy:.3f}, f1: {f1:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "        torch.save(model.state_dict(), f'models/{epoch+1}_lmepool_frontend_neg_class_{round(f1, 2)}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models/175_lmepool_frontend_neg_class_0.77.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "preds = []\n",
    "targs = []\n",
    "fns = []\n",
    "\n",
    "for num_specs in val_items_binned.keys():\n",
    "    valid_ds = MelspecShortishValidatioDataset(val_items_binned[num_specs], north_american_birds_common, negative_class_items_num_specs[num_specs])\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=2*16, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    fns += [item[1].name for item in valid_ds.items]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in valid_dl:\n",
    "            inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "            outputs = model(inputs)\n",
    "            preds.append(outputs.cpu().detach())\n",
    "            targs.append(labels.cpu().detach())\n",
    "\n",
    "preds = torch.cat(preds)\n",
    "targs = torch.cat(targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.767713004484305, 0.793859649122807)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1s), accuracy_score(preds.sigmoid() > ts[np.argmax(f1s)], targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[np.argmax(f1s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(860), tensor(223), tensor(280))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from birdcall.metrics import *\n",
    "\n",
    "preds_to_tp_fp_fn(preds, targs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
