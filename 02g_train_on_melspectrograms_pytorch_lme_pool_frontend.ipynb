{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdcall.data import *\n",
    "from birdcall.metrics import *\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_pickle('data/classes.pkl')\n",
    "train_ds = MelspecPoolDataset(pd.read_pickle('data/train_set.pkl'), classes, len_mult=60, normalize=False)\n",
    "valid_ds = MelspecPoolDataset(pd.read_pickle('data/val_set.pkl'), classes, len_mult=50, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15840, 13200)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=NUM_WORKERS)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=2*16, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "\n",
    "def lme_pool(x, alpha=1.0): # log-mean-exp pool\n",
    "    '''alpha -> approximates maxpool, alpha -> 0 approximates mean pool'''\n",
    "    T = x.shape[1]\n",
    "    mult_log = torch.log(torch.tensor(1/T))\n",
    "    return 1/alpha * (mult_log + torch.logsumexp((alpha * x), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrontEnd(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(80, affine=False)\n",
    "        self.register_parameter('alpha', torch.nn.Parameter(torch.tensor(0.)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, im_num, ch, y_dim, x_dim = x.shape\n",
    "        x = x ** torch.sigmoid(self.alpha)\n",
    "        x = x.view(-1, y_dim, x_dim)\n",
    "        x = self.bn(x)\n",
    "        return x.view(bs, im_num, ch, y_dim, x_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.frontend = FrontEnd()\n",
    "        self.cnn = nn.Sequential(*list(torchvision.models.resnet34(True).children())[:-2])\n",
    "        self.classifier = nn.Sequential(*[\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, len(classes))\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs, im_num, ch, y_dim, x_dim = x.shape\n",
    "        x = self.frontend(x)\n",
    "        x = self.cnn(x.view(-1, ch, y_dim, x_dim))\n",
    "        x = x.mean((2,3))\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(bs, im_num, -1)\n",
    "        x = lme_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model().cuda()\n",
    "# x = model(b[0].cuda())\n",
    "\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 22.3] loss: 0.023, acc: 0.000, f1: 0.000\n",
      "[10, 44.6] loss: 0.020, acc: 0.001, f1: 0.003\n",
      "[15, 66.9] loss: 0.019, acc: 0.015, f1: 0.039\n",
      "[20, 89.3] loss: 0.017, acc: 0.029, f1: 0.060\n",
      "[25, 111.6] loss: 0.015, acc: 0.097, f1: 0.178\n",
      "[30, 133.9] loss: 0.013, acc: 0.197, f1: 0.333\n",
      "[35, 156.4] loss: 0.012, acc: 0.314, f1: 0.471\n",
      "[40, 178.8] loss: 0.010, acc: 0.377, f1: 0.540\n",
      "[45, 201.3] loss: 0.009, acc: 0.413, f1: 0.576\n",
      "[50, 223.7] loss: 0.008, acc: 0.459, f1: 0.614\n",
      "[55, 246.2] loss: 0.008, acc: 0.462, f1: 0.621\n",
      "[60, 268.6] loss: 0.007, acc: 0.506, f1: 0.652\n",
      "[65, 291.1] loss: 0.006, acc: 0.534, f1: 0.674\n",
      "[70, 313.6] loss: 0.006, acc: 0.537, f1: 0.681\n",
      "[75, 336.1] loss: 0.005, acc: 0.557, f1: 0.696\n",
      "[80, 358.5] loss: 0.005, acc: 0.555, f1: 0.695\n",
      "[85, 381.0] loss: 0.005, acc: 0.578, f1: 0.710\n",
      "[90, 403.4] loss: 0.004, acc: 0.562, f1: 0.702\n",
      "[95, 425.7] loss: 0.004, acc: 0.578, f1: 0.708\n",
      "[100, 448.1] loss: 0.004, acc: 0.577, f1: 0.707\n",
      "[105, 470.4] loss: 0.004, acc: 0.572, f1: 0.702\n",
      "[110, 492.8] loss: 0.003, acc: 0.586, f1: 0.713\n",
      "[115, 515.1] loss: 0.003, acc: 0.579, f1: 0.711\n",
      "[120, 537.5] loss: 0.003, acc: 0.581, f1: 0.711\n",
      "[125, 559.9] loss: 0.003, acc: 0.584, f1: 0.714\n",
      "[130, 582.3] loss: 0.003, acc: 0.595, f1: 0.721\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for epoch in range(130):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        model.train()\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if np.isnan(loss.item()): \n",
    "            print(f'!!! nan encountered in loss !!! alpha: epoch: {epoch}\\n')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "    if epoch % 5 == 4:\n",
    "        model.eval();\n",
    "        preds = []\n",
    "        targs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in valid_dl:\n",
    "                inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                outputs = model(inputs)\n",
    "                preds.append(outputs.cpu().detach())\n",
    "                targs.append(labels.cpu().detach())\n",
    "\n",
    "            preds = torch.cat(preds)\n",
    "            targs = torch.cat(targs)\n",
    "\n",
    "        accuracy = accuracy_score(preds.sigmoid() > 0.5, targs)\n",
    "        f1 = f1_score(preds.sigmoid() > 0.5, targs, average='micro')\n",
    "        print(f'[{epoch + 1}, {(time.time() - t0)/60:.1f}] loss: {running_loss / (len(train_dl)-1):.3f}, acc: {accuracy:.3f}, f1: {f1:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "        torch.save(model.state_dict(), f'models/{epoch+1}_lmepool_frontend_{round(f1, 2)}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = []\n",
    "ts = []\n",
    "for t in np.linspace(0.4, 1, 61):\n",
    "    f1s.append(f1_score(preds.sigmoid() > t, targs, average='micro'))\n",
    "    ts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7215644209744626, 0.5946969696969697)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1s), accuracy_score(preds.sigmoid() > ts[np.argmax(f1s)], targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5700000000000001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[np.argmax(f1s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8610), tensor(2106), tensor(4590))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from birdcall.metrics import *\n",
    "\n",
    "preds_to_tp_fp_fn(preds, targs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
