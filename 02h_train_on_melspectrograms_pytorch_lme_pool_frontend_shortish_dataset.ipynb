{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdcall.data import *\n",
    "from birdcall.metrics import *\n",
    "from birdcall.ops import *\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "birdcall.data.MelspecShortishValidatioDataset"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MelspecShortishValidatioDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_pickle('data/classes.pkl')\n",
    "train_ds = MelspecShortishDataset(pd.read_pickle('data/train_set.pkl'), classes)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_sampler=BatchSampler(len_mult=60), num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "# valid_ds = MelspecShortishDataset(pd.read_pickle('data/val_set.pkl'), classes)\n",
    "# valid_dl = torch.utils.data.DataLoader(train_ds, batch_sampler=BatchSampler(len_mult=60), num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "valid_ds = MelspecPoolDataset(pd.read_pickle('data/val_set.pkl'), classes, len_mult=50, normalize=False)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=2*16, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrontEnd(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(80, affine=False)\n",
    "        self.register_parameter('alpha', torch.nn.Parameter(torch.tensor(0.)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, im_num, ch, y_dim, x_dim = x.shape\n",
    "        x = x ** torch.sigmoid(self.alpha)\n",
    "        x = x.view(-1, y_dim, x_dim)\n",
    "        x = self.bn(x)\n",
    "        return x.view(bs, im_num, ch, y_dim, x_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.frontend = FrontEnd()\n",
    "        self.cnn = nn.Sequential(*list(torchvision.models.resnet34(True).children())[:-2])\n",
    "        self.classifier = nn.Sequential(*[\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, len(classes))\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs, im_num, ch, y_dim, x_dim = x.shape\n",
    "        x = self.frontend(x)\n",
    "        x = self.cnn(x.view(-1, ch, y_dim, x_dim))\n",
    "        x = x.mean((2,3))\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(bs, im_num, -1)\n",
    "        x = lme_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 12.3] loss: 0.025, acc: 0.000, f1: 0.000\n",
      "[10, 24.3] loss: 0.024, acc: 0.000, f1: 0.000\n",
      "[15, 36.3] loss: 0.023, acc: 0.000, f1: 0.000\n",
      "[20, 48.4] loss: 0.021, acc: 0.002, f1: 0.006\n",
      "[25, 60.4] loss: 0.020, acc: 0.003, f1: 0.006\n",
      "[30, 72.6] loss: 0.020, acc: 0.002, f1: 0.008\n",
      "[35, 84.7] loss: 0.019, acc: 0.004, f1: 0.021\n",
      "[40, 97.0] loss: 0.019, acc: 0.011, f1: 0.029\n",
      "[45, 109.4] loss: 0.018, acc: 0.017, f1: 0.044\n",
      "[50, 121.6] loss: 0.018, acc: 0.025, f1: 0.055\n",
      "[55, 133.8] loss: 0.018, acc: 0.029, f1: 0.066\n",
      "[60, 145.9] loss: 0.017, acc: 0.037, f1: 0.071\n",
      "[65, 158.2] loss: 0.017, acc: 0.040, f1: 0.069\n",
      "[70, 170.5] loss: 0.016, acc: 0.055, f1: 0.121\n",
      "[75, 182.7] loss: 0.016, acc: 0.051, f1: 0.110\n",
      "[80, 195.0] loss: 0.016, acc: 0.060, f1: 0.141\n",
      "[85, 207.6] loss: 0.015, acc: 0.091, f1: 0.160\n",
      "[90, 220.0] loss: 0.015, acc: 0.081, f1: 0.123\n",
      "[95, 232.4] loss: 0.016, acc: 0.073, f1: 0.110\n",
      "[100, 245.1] loss: 0.014, acc: 0.103, f1: 0.166\n",
      "[105, 257.4] loss: 0.014, acc: 0.124, f1: 0.208\n",
      "[110, 270.0] loss: 0.014, acc: 0.106, f1: 0.158\n",
      "[115, 282.3] loss: 0.013, acc: 0.128, f1: 0.226\n",
      "[120, 295.0] loss: 0.013, acc: 0.169, f1: 0.263\n",
      "[125, 307.4] loss: 0.013, acc: 0.161, f1: 0.171\n",
      "[130, 319.6] loss: 0.012, acc: 0.220, f1: 0.328\n",
      "[135, 331.9] loss: 0.012, acc: 0.230, f1: 0.246\n",
      "[140, 344.1] loss: 0.011, acc: 0.224, f1: 0.270\n",
      "[145, 356.5] loss: 0.012, acc: 0.236, f1: 0.286\n",
      "[150, 368.7] loss: 0.011, acc: 0.273, f1: 0.371\n",
      "[155, 381.2] loss: 0.010, acc: 0.286, f1: 0.272\n",
      "[160, 393.8] loss: 0.010, acc: 0.311, f1: 0.426\n",
      "[165, 406.1] loss: 0.010, acc: 0.323, f1: 0.434\n",
      "[170, 418.6] loss: 0.010, acc: 0.308, f1: 0.336\n",
      "[175, 430.8] loss: 0.009, acc: 0.321, f1: 0.426\n",
      "[180, 443.1] loss: 0.009, acc: 0.344, f1: 0.463\n",
      "[185, 455.4] loss: 0.009, acc: 0.345, f1: 0.391\n",
      "[190, 467.9] loss: 0.009, acc: 0.325, f1: 0.446\n",
      "[195, 479.9] loss: 0.008, acc: 0.366, f1: 0.454\n",
      "[200, 492.4] loss: 0.008, acc: 0.371, f1: 0.462\n",
      "[205, 504.9] loss: 0.007, acc: 0.354, f1: 0.446\n",
      "[210, 517.3] loss: 0.008, acc: 0.375, f1: 0.413\n",
      "[215, 529.7] loss: 0.007, acc: 0.403, f1: 0.546\n",
      "[220, 542.2] loss: 0.007, acc: 0.414, f1: 0.573\n",
      "[225, 554.9] loss: 0.007, acc: 0.411, f1: 0.453\n",
      "[230, 567.2] loss: 0.006, acc: 0.426, f1: 0.579\n",
      "[235, 579.5] loss: 0.006, acc: 0.347, f1: 0.307\n",
      "[240, 592.1] loss: 0.006, acc: 0.414, f1: 0.388\n",
      "[245, 604.6] loss: 0.005, acc: 0.415, f1: 0.564\n",
      "[250, 616.8] loss: 0.006, acc: 0.437, f1: 0.569\n",
      "[255, 629.3] loss: 0.006, acc: 0.416, f1: 0.498\n",
      "[260, 641.7] loss: 0.005, acc: 0.439, f1: 0.579\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for epoch in range(260):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        model.train()\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if np.isnan(loss.item()): \n",
    "            print(f'!!! nan encountered in loss !!! alpha: epoch: {epoch}\\n')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "    if epoch % 5 == 4:\n",
    "        model.eval();\n",
    "        preds = []\n",
    "        targs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in valid_dl:\n",
    "                inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                outputs = model(inputs)\n",
    "                preds.append(outputs.cpu().detach())\n",
    "                targs.append(labels.cpu().detach())\n",
    "\n",
    "            preds = torch.cat(preds)\n",
    "            targs = torch.cat(targs)\n",
    "\n",
    "        accuracy = accuracy_score(preds.sigmoid() > 0.5, targs)\n",
    "        f1 = f1_score(preds.sigmoid() > 0.5, targs, average='micro')\n",
    "        print(f'[{epoch + 1}, {(time.time() - t0)/60:.1f}] loss: {running_loss / len(train_dl):.3f}, acc: {accuracy:.3f}, f1: {f1:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "        torch.save(model.state_dict(), f'models/{epoch+1}_lmepool_frontend_shortish_{round(f1, 2)}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = []\n",
    "ts = []\n",
    "for t in np.linspace(0.4, 1, 61):\n",
    "    f1s.append(f1_score(preds.sigmoid() > t, targs, average='micro'))\n",
    "    ts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5804704550965969, 0.43636363636363634)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1s), accuracy_score(preds.sigmoid() > ts[np.argmax(f1s)], targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43000000000000005"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[np.argmax(f1s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6479), tensor(2963), tensor(6721))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from birdcall.metrics import *\n",
    "\n",
    "preds_to_tp_fp_fn(preds, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[265, 12.3] loss: 0.005, acc: 0.447, f1: 0.584\n",
      "[270, 24.8] loss: 0.005, acc: 0.407, f1: 0.313\n",
      "[275, 37.3] loss: 0.005, acc: 0.448, f1: 0.573\n",
      "[280, 49.8] loss: 0.005, acc: 0.437, f1: 0.448\n",
      "[285, 62.0] loss: 0.005, acc: 0.398, f1: 0.553\n",
      "[290, 74.5] loss: 0.005, acc: 0.459, f1: 0.484\n",
      "[295, 86.8] loss: 0.005, acc: 0.467, f1: 0.599\n",
      "[300, 99.1] loss: 0.004, acc: 0.458, f1: 0.566\n",
      "[305, 111.3] loss: 0.004, acc: 0.432, f1: 0.194\n",
      "[310, 123.6] loss: 0.004, acc: 0.433, f1: 0.235\n",
      "[315, 136.2] loss: 0.004, acc: 0.460, f1: 0.434\n",
      "[320, 148.5] loss: 0.003, acc: 0.467, f1: 0.611\n",
      "[325, 161.1] loss: 0.004, acc: 0.468, f1: 0.387\n",
      "[330, 173.6] loss: 0.004, acc: 0.477, f1: 0.502\n",
      "[335, 186.3] loss: 0.004, acc: 0.469, f1: 0.568\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for epoch in range(260, 335):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        model.train()\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if np.isnan(loss.item()): \n",
    "            print(f'!!! nan encountered in loss !!! alpha: epoch: {epoch}\\n')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "    if epoch % 5 == 4:\n",
    "        model.eval();\n",
    "        preds = []\n",
    "        targs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in valid_dl:\n",
    "                inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                outputs = model(inputs)\n",
    "                preds.append(outputs.cpu().detach())\n",
    "                targs.append(labels.cpu().detach())\n",
    "\n",
    "            preds = torch.cat(preds)\n",
    "            targs = torch.cat(targs)\n",
    "\n",
    "        accuracy = accuracy_score(preds.sigmoid() > 0.5, targs)\n",
    "        f1 = f1_score(preds.sigmoid() > 0.5, targs, average='micro')\n",
    "        print(f'[{epoch + 1}, {(time.time() - t0)/60:.1f}] loss: {running_loss / len(train_dl):.3f}, acc: {accuracy:.3f}, f1: {f1:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "        torch.save(model.state_dict(), f'models/{epoch+1}_lmepool_frontend_shortish_{round(f1, 2)}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models/335_lmepool_frontend_shortish_0.57.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models/130_lmepool_frontend_0.72.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='models/130_lmepool_frontend_0.72.pth' target='_blank'>models/130_lmepool_frontend_0.72.pth</a><br>"
      ],
      "text/plain": [
       "/home/radek/workspace/birdcall/models/130_lmepool_frontend_0.72.pth"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('models/130_lmepool_frontend_0.72.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_items = bin_items(pd.read_pickle('data/val_set.pkl'), pd.read_pickle('data/classes.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.5 s, sys: 7.55 s, total: 39.1 s\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.eval();\n",
    "preds = []\n",
    "targs = []\n",
    "fns = []\n",
    "\n",
    "for num_specs in val_items.keys():\n",
    "    valid_ds = MelspecShortishValidatioDataset(val_items[num_specs], pd.read_pickle('data/classes.pkl'))\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_ds, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    fns += [item[1].name for item in valid_ds.items]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in valid_dl:\n",
    "            inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "            outputs = model(inputs)\n",
    "            preds.append(outputs.cpu().detach())\n",
    "            targs.append(labels.cpu().detach())\n",
    "\n",
    "preds = torch.cat(preds)\n",
    "targs = torch.cat(targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6055796055796056, 0.7320735179911985)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(preds.sigmoid() > 0.5, targs)\n",
    "f1 = f1_score(preds.sigmoid() > 0.5, targs, average='micro')\n",
    "accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5161135161135161, 0.5741515574151557)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy = accuracy_score(preds.sigmoid() > 0.5, targs)\n",
    "# f1 = f1_score(preds.sigmoid() > 0.5, targs, average='micro')\n",
    "# accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = []\n",
    "ts = []\n",
    "for t in np.linspace(0.4, 1, 61):\n",
    "    f1s.append(f1_score(preds.sigmoid() > t, targs, average='micro'))\n",
    "    ts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6089466089466089, 0.7345473198255963)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(preds.sigmoid() > ts[np.argmax(f1s)], targs), max(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[np.argmax(f1s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1368), tensor(312), tensor(711))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from birdcall.metrics import *\n",
    "\n",
    "preds_to_tp_fp_fn(preds, targs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
