{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdcall.data import *\n",
    "\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = pd.read_pickle('data/recs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfftw.builders import rfft as rfft_builder\n",
    "from pyfftw import empty_aligned\n",
    "\n",
    "mel_bands=80\n",
    "mel_min=27.5\n",
    "mel_max=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(samples, sample_rate, frame_len, fps, batch=48, dtype=None,\n",
    "                bins=None, plans=None):\n",
    "    \"\"\"\n",
    "    Computes a magnitude spectrogram for a given vector of samples at a given\n",
    "    sample rate (in Hz), frame length (in samples) and frame rate (in Hz).\n",
    "    Allows to transform multiple frames at once for improved performance (with\n",
    "    a default value of 48, more is not always better). Returns a numpy array.\n",
    "    Allows to return a limited number of bins only, with improved performance\n",
    "    over discarding them afterwards. Optionally accepts a set of precomputed\n",
    "    plans created with spectrogram_plans(), required when multi-threading.\n",
    "    \"\"\"\n",
    "    if dtype is None:\n",
    "        dtype = samples.dtype\n",
    "    if bins is None:\n",
    "        bins = frame_len // 2 + 1\n",
    "    if len(samples) < frame_len:\n",
    "        return np.empty((0, bins), dtype=dtype)\n",
    "    if plans is None:\n",
    "        plans = spectrogram_plans(frame_len, batch, dtype)\n",
    "    rfft1, rfft, win = plans\n",
    "    hopsize = int(sample_rate // fps)\n",
    "    num_frames = (len(samples) - frame_len) // hopsize + 1\n",
    "    nabs = np.abs\n",
    "    naa = np.asanyarray\n",
    "    if batch > 1 and num_frames >= batch and samples.flags.c_contiguous:\n",
    "        frames = np.lib.stride_tricks.as_strided(\n",
    "                samples, shape=(num_frames, frame_len),\n",
    "                strides=(samples.strides[0] * hopsize, samples.strides[0]))\n",
    "        spect = [nabs(rfft(naa(frames[pos:pos + batch:], dtype) * win)[:, :bins])\n",
    "                 for pos in range(0, num_frames - batch + 1, batch)]\n",
    "        samples = samples[(num_frames // batch * batch) * hopsize::]\n",
    "        num_frames = num_frames % batch\n",
    "    else:\n",
    "        spect = []\n",
    "    if num_frames:\n",
    "        spect.append(np.vstack(\n",
    "                [nabs(rfft1(naa(samples[pos:pos + frame_len:],\n",
    "                                dtype) * win)[:bins:])\n",
    "                 for pos in range(0, len(samples) - frame_len + 1, hopsize)]))\n",
    "    return np.vstack(spect) if len(spect) > 1 else spect[0]\n",
    "\n",
    "\n",
    "def create_mel_filterbank(sample_rate, frame_len, num_bands, min_freq,\n",
    "                          max_freq):\n",
    "    \"\"\"\n",
    "    Creates a mel filterbank of `num_bands` triangular filters, with the first\n",
    "    filter starting at `min_freq` and the last one stopping at `max_freq`.\n",
    "    Returns the filterbank as a matrix suitable for a dot product against\n",
    "    magnitude spectra created from samples at a sample rate of `sample_rate`\n",
    "    with a window length of `frame_len` samples.\n",
    "    \"\"\"\n",
    "    # prepare output matrix\n",
    "    input_bins = (frame_len // 2) + 1\n",
    "    filterbank = np.zeros((input_bins, num_bands))\n",
    "\n",
    "    # mel-spaced peak frequencies\n",
    "    min_mel = 1127 * np.log1p(min_freq / 700.0)\n",
    "    max_mel = 1127 * np.log1p(max_freq / 700.0)\n",
    "    spacing = (max_mel - min_mel) / (num_bands + 1)\n",
    "    peaks_mel = min_mel + np.arange(num_bands + 2) * spacing\n",
    "    peaks_hz = 700 * (np.exp(peaks_mel / 1127) - 1)\n",
    "    fft_freqs = np.linspace(0, sample_rate / 2., input_bins)\n",
    "    peaks_bin = np.searchsorted(fft_freqs, peaks_hz)\n",
    "\n",
    "    # fill output matrix with triangular filters\n",
    "    for b, filt in enumerate(filterbank.T):\n",
    "        # The triangle starts at the previous filter's peak (peaks_freq[b]),\n",
    "        # has its maximum at peaks_freq[b+1] and ends at peaks_freq[b+2].\n",
    "        left_hz, top_hz, right_hz = peaks_hz[b:b + 3]  # b, b+1, b+2\n",
    "        left_bin, top_bin, right_bin = peaks_bin[b:b + 3]\n",
    "        # Create triangular filter compatible to yaafe\n",
    "        filt[left_bin:top_bin] = ((fft_freqs[left_bin:top_bin] - left_hz) /\n",
    "                                  (top_bin - left_bin))\n",
    "        filt[top_bin:right_bin] = ((right_hz - fft_freqs[top_bin:right_bin]) /\n",
    "                                   (right_bin - top_bin))\n",
    "        filt[left_bin:right_bin] /= filt[left_bin:right_bin].sum()\n",
    "\n",
    "    return filterbank\n",
    "\n",
    "def spectrogram_plans(frame_len, batch=48, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Precompute plans for spectrogram(), for a given frame length, batch size\n",
    "    and dtype. Returns two plans (single spectrum and batch), and a window.\n",
    "    \"\"\"\n",
    "    input_array = empty_aligned((batch, frame_len), dtype=dtype)\n",
    "    win = np.hanning(frame_len).astype(dtype)\n",
    "    return (rfft_builder(input_array[0]), rfft_builder(input_array), win)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling it all together into a datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export data\n",
    "\n",
    "filterbank = create_mel_filterbank(SAMPLE_RATE, 256, mel_bands, mel_min, mel_max)\n",
    "def audio_to_melspec(audio):\n",
    "    spec = spectrogram(audio, SAMPLE_RATE, 256, 128)\n",
    "    return (spec @ filterbank).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export data\n",
    "\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool\n",
    "import torch\n",
    "\n",
    "def create_example(item):\n",
    "    cls_idx, path, num_specs = item\n",
    "    x, _ = sf.read(path)\n",
    "\n",
    "    example_duration = num_specs * 5 * SAMPLE_RATE\n",
    "    if x.shape[0] < example_duration:\n",
    "        x = np.tile(x, example_duration // x.shape[0] + 1)\n",
    "    \n",
    "    start_frame = np.random.randint(0, x.shape[0] - example_duration+1)\n",
    "    x = x[start_frame:start_frame+example_duration]\n",
    "\n",
    "    xs = []\n",
    "    for i in range(num_specs):\n",
    "        for j in range(3):\n",
    "            start_frame = int((i * 3 + j) * 1.66 * SAMPLE_RATE)\n",
    "            xs.append(x[start_frame:start_frame+int(1.66*SAMPLE_RATE)])\n",
    "\n",
    "    specs = []\n",
    "    for x in xs:\n",
    "        specs.append(audio_to_melspec(x))\n",
    "    specs = np.stack(specs)\n",
    "    imgs = specs.reshape(-1, 3, 80, 212)\n",
    "\n",
    "    one_hot = np.zeros((264))\n",
    "    one_hot[cls_idx] = 1\n",
    "\n",
    "    return imgs.astype(np.float32), one_hot\n",
    "\n",
    "def bin_items(recs, classes):\n",
    "    binned_items = defaultdict(list)\n",
    "    for key in recs.keys():\n",
    "        for path, duration in recs[key]:\n",
    "            if duration < 7.5: binned_items[1].append((classes.index(key), path, 1))\n",
    "            elif duration < 12.5: binned_items[2].append((classes.index(key), path, 2))\n",
    "            elif duration < 25: binned_items[4].append((classes.index(key), path, 4))\n",
    "            elif duration < 45: binned_items[6].append((classes.index(key), path, 6))\n",
    "            else: binned_items[10].append((classes.index(key), path, 10))\n",
    "    return binned_items\n",
    "\n",
    "class MelspecShortishDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, recs, classes):\n",
    "        self.recs = recs\n",
    "        self.classes = classes\n",
    "        self.binned_items = bin_items(recs, classes)\n",
    "        \n",
    "    def __len__(self): raise(NotImplementedError)       \n",
    "\n",
    "    def __getitem__(self, bin_num):\n",
    "        item_idx = np.random.randint(0, len(self.binned_items[bin_num]))\n",
    "        item = self.binned_items[bin_num][item_idx]\n",
    "        return create_example(item)\n",
    "    \n",
    "def batch_sampler(batch_size=16, len_mult=1):\n",
    "    for i in range(len_mult * 264 // batch_size):\n",
    "        chosen_bin = np.random.choice([1,2,4,6,10], p=[0.1, 0.225, 0.225, 0.225, 0.225])\n",
    "        yield [chosen_bin] * batch_size\n",
    "\n",
    "class BatchSampler():\n",
    "    def __init__(self, batch_size=16, len_mult=1):\n",
    "        self.batch_size = batch_size\n",
    "        self.len_mult = len_mult\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return batch_sampler(self.batch_size, self.len_mult)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_mult * 264 // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MelspecShortishDataset(pd.read_pickle('data/train_set.pkl'), pd.read_pickle('data/classes.pkl'))\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_sampler=BatchSampler(), num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 224 ms, total: 248 ms\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for batch in train_dl:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export data\n",
    "\n",
    "class MelspecShortishValidatioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, items, classes):\n",
    "        self.classes = classes\n",
    "        self.items = items\n",
    "                \n",
    "    def __len__(self): return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.create_example(self.items[idx])\n",
    "    \n",
    "    def create_example(self, item):\n",
    "        cls_idx, path, num_specs = item\n",
    "        if path.name.split('.')[1] == 'wav':\n",
    "            x, _ = sf.read(path)\n",
    "\n",
    "            example_duration = num_specs * 5 * SAMPLE_RATE\n",
    "            if x.shape[0] < example_duration:\n",
    "                x = np.tile(x, example_duration // x.shape[0] + 1)\n",
    "\n",
    "            start_frame = 0\n",
    "            x = x[start_frame:example_duration]\n",
    "\n",
    "            xs = []\n",
    "            for i in range(num_specs):\n",
    "                for j in range(3):\n",
    "                    start_frame = int((i * 3 + j) * 1.66 * SAMPLE_RATE)\n",
    "                    xs.append(x[start_frame:start_frame+int(1.66*SAMPLE_RATE)])\n",
    "\n",
    "            specs = []\n",
    "            for x in xs:\n",
    "                specs.append(audio_to_melspec(x))\n",
    "        else: # .npy\n",
    "            frames_per_spec = 212\n",
    "            x = np.load(path)\n",
    "            example_duration = num_specs * 3 * frames_per_spec\n",
    "            \n",
    "            if x.shape[1] < example_duration:\n",
    "                x = np.tile(x, (example_duration // x.shape[1] + 1))\n",
    "                \n",
    "            specs = []\n",
    "            for i in range(num_specs):\n",
    "                for j in range(3):\n",
    "                    start_frame = int((i * 3 + j) * frames_per_spec)\n",
    "                    specs.append(x[:, start_frame:start_frame+frames_per_spec])\n",
    "            \n",
    "        specs = np.stack(specs)\n",
    "        imgs = specs.reshape(-1, 3, 80, 212)\n",
    "\n",
    "        one_hot = np.zeros((264))\n",
    "        one_hot[cls_idx] = 1\n",
    "\n",
    "        return imgs.astype(np.float32), one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_items = bin_items(recs, pd.read_pickle('data/classes.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_specs in val_items.keys():\n",
    "    valid_ds = MelspecShortishValidatioDataset(val_items[num_specs], pd.read_pickle('data/classes.pkl'))\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_ds, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Saving spectrograms to disk to speed up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for directory in Path('data/train_resampled/').iterdir():\n",
    "    ebird_code = directory.name\n",
    "    for recording in directory.iterdir():\n",
    "        if recording.stem in ['XC487556', 'XC487557', 'XC246425']: continue\n",
    "\n",
    "        !mkdir -p data/npy/train_resampled/{ebird_code}\n",
    "        x = sf.read(recording)[0]\n",
    "        x = audio_to_melspec(x).astype(np.float32)\n",
    "        np.save(f'data/npy/train_resampled/{ebird_code}/{recording.stem}.npy', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p data/npy/shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 s, sys: 2.86 s, total: 25.3 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for recording in Path('data/shifted/').iterdir():\n",
    "    x = sf.read(recording)[0]\n",
    "    x = audio_to_melspec(x).astype(np.float32)\n",
    "    np.save(f'data/npy/shifted/{recording.stem}.npy', x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
