{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdcall.data import *\n",
    "from birdcall.metrics import *\n",
    "from birdcall.ops import *\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = pd.read_pickle('data/splits.pkl')\n",
    "positive_class_items = pd.read_pickle('data/positive_class_items.pkl')\n",
    "negative_class_items = pd.read_pickle('data/negative_class_items.pkl')\n",
    "north_american_birds_common = pd.read_pickle('data/north_american_birds_common.pkl')\n",
    "all_classes = pd.read_pickle('data/classes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_items = np.array(positive_class_items)[splits[0][0]].tolist()\n",
    "val_items = np.array(positive_class_items)[splits[0][1]].tolist()\n",
    "negative_class_items = [(-1, item[1], item[2]) for item in negative_class_items]\n",
    "\n",
    "train_items = translate_class(train_items, all_classes, north_american_birds_common)\n",
    "val_items = translate_class(val_items, all_classes, north_american_birds_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_pickle('data/classes.pkl')\n",
    "north_american_birds_common = pd.read_pickle('data/north_american_birds_common.pkl')\n",
    "\n",
    "train_ds = MelspecPoolDatasetNegativeClass(train_items, negative_class_items, north_american_birds_common, len_mult=300, reshape_to_3ch=False)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, num_workers=NUM_WORKERS, pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_items_binned = bin_items_negative_class(val_items)\n",
    "\n",
    "np.random.shuffle(negative_class_items)\n",
    "negative_class_items = negative_class_items[:2500]\n",
    "negative_class_items_binned = bin_items_negative_class(negative_class_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrontEnd(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(80, affine=False)\n",
    "        self.register_parameter('alpha', torch.nn.Parameter(torch.tensor(0.)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, ch, y_dim, x_dim = x.shape\n",
    "        x = x ** torch.sigmoid(self.alpha)\n",
    "        x = x.view(-1, y_dim, x_dim)\n",
    "        x = self.bn(x)\n",
    "        return x.view(bs, ch, y_dim, x_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Body(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, 64, 3),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.Conv2d(128, 128, 3),\n",
    "            nn.Conv2d(128, 128, (17,3)),\n",
    "            nn.Conv2d(128, 1024, (1,21)),\n",
    "            nn.Conv2d(1024, 1024, (1,1)),\n",
    "            nn.Conv2d(1024, num_classes, (1,1))\n",
    "        ])\n",
    "        self.bns = nn.ModuleList([\n",
    "            nn.BatchNorm1d(78),\n",
    "            nn.BatchNorm1d(76),\n",
    "            nn.BatchNorm1d(23),\n",
    "            nn.BatchNorm1d(21),\n",
    "            nn.BatchNorm1d(5),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.BatchNorm1d(1),\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        bs, ch = x.shape[:2]\n",
    "        x = x.view(-1, 1, x.shape[-2], x.shape[-1])\n",
    "        for i in range(2):\n",
    "            x = self.convs[i](x)\n",
    "            x = nn.functional.leaky_relu_(x)\n",
    "            x = x.view(-1, x.shape[-2], x.shape[-1])\n",
    "            x = self.bns[i](x)\n",
    "            x = x.view(bs * ch, -1, x.shape[-2], x.shape[-1])\n",
    "\n",
    "        x = nn.functional.max_pool2d(x, (3,3))\n",
    "        \n",
    "        for i in range(2, 5):\n",
    "            x = self.convs[i](x)\n",
    "            x = nn.functional.leaky_relu_(x)\n",
    "            if i == 4: x = nn.functional.dropout2d(x, 0.5)\n",
    "            x = x.view(-1, x.shape[-2], x.shape[-1])\n",
    "            x = self.bns[i](x)\n",
    "            x = x.view(bs * ch, -1, x.shape[-2], x.shape[-1])\n",
    "        \n",
    "        x = nn.functional.max_pool2d(x, (5,3))\n",
    "\n",
    "        for i in range(5, 7):\n",
    "            x = self.convs[i](x)\n",
    "            x = nn.functional.leaky_relu_(x)\n",
    "            x = nn.functional.dropout2d(x, 0.5)\n",
    "            x = x.view(-1, x.shape[-2], x.shape[-1])\n",
    "            x = self.bns[i](x)\n",
    "            x = x.view(bs * ch, -1, x.shape[-2], x.shape[-1])\n",
    "        \n",
    "        x = self.convs[-1](x)\n",
    "        return x.view(bs, ch, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.frontend = FrontEnd()\n",
    "        self.body = Body(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.frontend(x)\n",
    "        x = self.body(x)\n",
    "        x = lme_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_classes=len(north_american_birds_common)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 16.6] loss: 0.051, acc: 0.687, f1: 0.000\n",
      "[2, 32.8] loss: 0.047, acc: 0.687, f1: 0.002\n",
      "[3, 48.9] loss: 0.044, acc: 0.680, f1: 0.010\n",
      "[4, 65.1] loss: 0.041, acc: 0.656, f1: 0.037\n",
      "[5, 81.3] loss: 0.038, acc: 0.644, f1: 0.080\n",
      "[6, 97.5] loss: 0.034, acc: 0.645, f1: 0.129\n",
      "[7, 113.7] loss: 0.032, acc: 0.645, f1: 0.203\n",
      "[8, 129.9] loss: 0.029, acc: 0.647, f1: 0.207\n",
      "[9, 146.1] loss: 0.027, acc: 0.694, f1: 0.268\n",
      "[10, 162.3] loss: 0.025, acc: 0.689, f1: 0.326\n",
      "[11, 178.5] loss: 0.024, acc: 0.695, f1: 0.334\n",
      "[12, 194.7] loss: 0.023, acc: 0.691, f1: 0.379\n",
      "[13, 210.9] loss: 0.021, acc: 0.704, f1: 0.367\n",
      "[14, 227.1] loss: 0.020, acc: 0.711, f1: 0.400\n",
      "[15, 243.3] loss: 0.019, acc: 0.704, f1: 0.412\n",
      "[16, 259.5] loss: 0.018, acc: 0.720, f1: 0.406\n",
      "[17, 275.7] loss: 0.017, acc: 0.721, f1: 0.430\n",
      "[18, 291.9] loss: 0.017, acc: 0.714, f1: 0.430\n",
      "[19, 308.1] loss: 0.016, acc: 0.729, f1: 0.470\n",
      "[20, 324.3] loss: 0.016, acc: 0.731, f1: 0.470\n",
      "[21, 340.5] loss: 0.015, acc: 0.741, f1: 0.495\n",
      "[22, 356.7] loss: 0.015, acc: 0.716, f1: 0.473\n",
      "[23, 372.9] loss: 0.014, acc: 0.740, f1: 0.490\n",
      "[24, 389.1] loss: 0.014, acc: 0.733, f1: 0.489\n",
      "[25, 405.3] loss: 0.013, acc: 0.728, f1: 0.507\n",
      "[26, 421.5] loss: 0.012, acc: 0.747, f1: 0.525\n",
      "[27, 437.7] loss: 0.012, acc: 0.731, f1: 0.502\n",
      "[28, 453.9] loss: 0.012, acc: 0.748, f1: 0.516\n",
      "[29, 470.1] loss: 0.011, acc: 0.748, f1: 0.529\n",
      "[30, 486.3] loss: 0.011, acc: 0.741, f1: 0.523\n",
      "[31, 502.5] loss: 0.011, acc: 0.766, f1: 0.548\n",
      "[32, 518.7] loss: 0.011, acc: 0.751, f1: 0.530\n",
      "[33, 534.9] loss: 0.010, acc: 0.746, f1: 0.525\n",
      "[34, 551.1] loss: 0.010, acc: 0.756, f1: 0.546\n",
      "[35, 567.3] loss: 0.010, acc: 0.761, f1: 0.549\n",
      "[36, 583.5] loss: 0.009, acc: 0.761, f1: 0.542\n",
      "[37, 599.7] loss: 0.009, acc: 0.741, f1: 0.527\n",
      "[38, 615.9] loss: 0.009, acc: 0.745, f1: 0.539\n",
      "[39, 632.1] loss: 0.009, acc: 0.753, f1: 0.541\n",
      "[40, 648.3] loss: 0.008, acc: 0.754, f1: 0.546\n",
      "[41, 664.5] loss: 0.009, acc: 0.754, f1: 0.545\n",
      "[42, 680.8] loss: 0.008, acc: 0.753, f1: 0.537\n",
      "[43, 697.0] loss: 0.008, acc: 0.754, f1: 0.553\n",
      "[44, 713.2] loss: 0.008, acc: 0.764, f1: 0.551\n",
      "[45, 729.4] loss: 0.008, acc: 0.751, f1: 0.553\n",
      "[46, 745.6] loss: 0.008, acc: 0.756, f1: 0.544\n",
      "[47, 761.8] loss: 0.007, acc: 0.758, f1: 0.571\n",
      "[48, 778.0] loss: 0.008, acc: 0.757, f1: 0.559\n",
      "[49, 794.2] loss: 0.007, acc: 0.748, f1: 0.549\n",
      "[50, 810.4] loss: 0.007, acc: 0.754, f1: 0.552\n",
      "[51, 826.6] loss: 0.007, acc: 0.745, f1: 0.559\n",
      "[52, 842.9] loss: 0.007, acc: 0.752, f1: 0.551\n",
      "[53, 859.1] loss: 0.007, acc: 0.759, f1: 0.559\n",
      "[54, 875.3] loss: 0.006, acc: 0.751, f1: 0.565\n",
      "[55, 891.5] loss: 0.006, acc: 0.766, f1: 0.575\n",
      "[56, 907.7] loss: 0.006, acc: 0.762, f1: 0.566\n",
      "[57, 923.9] loss: 0.006, acc: 0.776, f1: 0.588\n",
      "[58, 940.1] loss: 0.006, acc: 0.776, f1: 0.576\n",
      "[59, 956.3] loss: 0.006, acc: 0.754, f1: 0.565\n",
      "[60, 972.5] loss: 0.006, acc: 0.748, f1: 0.560\n",
      "[61, 988.7] loss: 0.006, acc: 0.771, f1: 0.570\n",
      "[62, 1004.9] loss: 0.006, acc: 0.761, f1: 0.567\n",
      "[63, 1021.1] loss: 0.006, acc: 0.771, f1: 0.583\n",
      "[64, 1037.3] loss: 0.006, acc: 0.772, f1: 0.584\n",
      "[65, 1053.5] loss: 0.005, acc: 0.755, f1: 0.570\n",
      "[66, 1069.7] loss: 0.005, acc: 0.770, f1: 0.583\n",
      "[67, 1085.9] loss: 0.006, acc: 0.763, f1: 0.557\n",
      "[68, 1102.1] loss: 0.005, acc: 0.744, f1: 0.567\n",
      "[69, 1118.3] loss: 0.005, acc: 0.758, f1: 0.569\n",
      "[70, 1134.5] loss: 0.005, acc: 0.757, f1: 0.574\n",
      "[71, 1150.7] loss: 0.005, acc: 0.780, f1: 0.584\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for epoch in range(130):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        model.train()\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if np.isnan(loss.item()): \n",
    "            print(f'!!! nan encountered in loss !!! alpha: epoch: {epoch}\\n')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    model.eval();\n",
    "    preds = []\n",
    "    targs = []\n",
    "\n",
    "    for num_specs in val_items_binned.keys():\n",
    "        valid_ds = MelspecShortishValidatioDataset(val_items_binned[num_specs], north_american_birds_common, negative_class_items_binned[num_specs], reshape_to_3ch=False)\n",
    "        valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=2*16, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in valid_dl:\n",
    "                inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                outputs = model(inputs)\n",
    "                preds.append(outputs.cpu().detach())\n",
    "                targs.append(labels.cpu().detach())\n",
    "\n",
    "    preds = torch.cat(preds)\n",
    "    targs = torch.cat(targs)\n",
    "\n",
    "    accuracy = accuracy_score(preds.sigmoid() > 0.5, targs)\n",
    "    f1 = f1_score(preds.sigmoid() > 0.5, targs, average='micro')\n",
    "    print(f'[{epoch + 1}, {(time.time() - t0)/60:.1f}] loss: {running_loss / (len(train_dl)-1):.3f}, acc: {accuracy:.3f}, f1: {f1:.3f}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "    if epoch % 5 == 4: torch.save(model.state_dict(), f'models/{epoch+1}_lmepool_frontend_neg_nocnn_{round(f1, 2)}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = []\n",
    "ts = []\n",
    "for t in np.linspace(0.4, 1, 61):\n",
    "    f1s.append(f1_score(preds.sigmoid() > t, targs, average='micro'))\n",
    "    ts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(f1s), accuracy_score(preds.sigmoid() > ts[np.argmax(f1s)], targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[np.argmax(f1s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdcall.metrics import *\n",
    "\n",
    "preds_to_tp_fp_fn(preds, targs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
