{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdcall.data import *\n",
    "from birdcall.metrics import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_pickle('data/classes.pkl')\n",
    "train_ds = MelspecPoolDataset(pd.read_pickle('data/train_set.pkl'), classes, len_mult=60)\n",
    "valid_ds = MelspecPoolDataset(pd.read_pickle('data/val_set.pkl'), classes, len_mult=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15840, 2640)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=NUM_WORKERS)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=2*16, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 10, 3, 80, 212]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for b in train_dl: break\n",
    "b[0].shape, b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0715), tensor(0.8814))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].mean(), b[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lme_pool(x, alpha=1.0): # log-mean-exp pool\n",
    "    '''alpha -> approximates maxpool, alpha -> 0 approximates mean pool'''\n",
    "    T = x.shape[1]\n",
    "    return 1/alpha * torch.log(1/T * torch.exp(alpha * x).sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(*list(torchvision.models.resnet34(True).children())[:-2])\n",
    "        self.classifier = nn.Sequential(*[\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, len(classes))\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs, im_num, ch, y_dim, x_dim = x.shape\n",
    "        x = self.cnn(x.view(-1, ch, y_dim, x_dim))\n",
    "        x = x.mean((2,3))\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(bs, im_num, -1)\n",
    "        x = lme_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 269.1] loss: 0.122, acc: 0.000, f1: 0.000\n",
      "[3, 270.6] loss: 0.025, acc: 0.000, f1: 0.000\n",
      "[4, 269.7] loss: 0.024, acc: 0.000, f1: 0.000\n",
      "[5, 271.1] loss: 0.024, acc: 0.000, f1: 0.000\n",
      "[6, 270.6] loss: 0.023, acc: 0.000, f1: 0.000\n",
      "[7, 270.7] loss: 0.022, acc: 0.000, f1: 0.000\n",
      "[8, 269.3] loss: 0.022, acc: 0.000, f1: 0.000\n",
      "[9, 269.1] loss: 0.022, acc: 0.000, f1: 0.000\n",
      "[10, 270.6] loss: 0.021, acc: 0.000, f1: 0.000\n",
      "[11, 271.1] loss: 0.021, acc: 0.000, f1: 0.000\n",
      "[12, 269.2] loss: 0.021, acc: 0.000, f1: 0.000\n",
      "[13, 269.6] loss: 0.021, acc: 0.000, f1: 0.000\n",
      "[14, 269.6] loss: 0.020, acc: 0.000, f1: 0.000\n",
      "[15, 269.2] loss: 0.020, acc: 0.002, f1: 0.003\n",
      "[16, 268.7] loss: 0.020, acc: 0.003, f1: 0.007\n",
      "[17, 269.5] loss: 0.019, acc: 0.005, f1: 0.009\n",
      "[18, 269.8] loss: 0.019, acc: 0.004, f1: 0.010\n",
      "[19, 269.9] loss: 0.019, acc: 0.007, f1: 0.015\n",
      "[20, 270.0] loss: 0.019, acc: 0.007, f1: 0.014\n",
      "[21, 269.3] loss: 0.018, acc: 0.011, f1: 0.022\n",
      "[22, 269.0] loss: 0.018, acc: 0.010, f1: 0.023\n",
      "[23, 270.2] loss: 0.018, acc: 0.013, f1: 0.027\n",
      "[24, 268.7] loss: 0.018, acc: 0.014, f1: 0.029\n",
      "[25, 268.8] loss: 0.018, acc: 0.027, f1: 0.055\n",
      "[27, 269.0] loss: 0.017, acc: 0.047, f1: 0.095\n",
      "[28, 269.0] loss: 0.017, acc: 0.039, f1: 0.079\n",
      "[29, 271.0] loss: 0.017, acc: 0.045, f1: 0.091\n",
      "[30, 270.8] loss: 0.017, acc: 0.050, f1: 0.112\n",
      "[31, 269.8] loss: 0.016, acc: 0.053, f1: 0.110\n",
      "[32, 269.2] loss: 0.017, acc: 0.050, f1: 0.099\n",
      "[33, 270.0] loss: 0.016, acc: 0.070, f1: 0.139\n",
      "[34, 268.9] loss: 0.016, acc: 0.060, f1: 0.126\n",
      "[35, 270.8] loss: 0.016, acc: 0.070, f1: 0.142\n",
      "[36, 269.9] loss: 0.016, acc: 0.068, f1: 0.135\n",
      "[37, 270.6] loss: 0.015, acc: 0.098, f1: 0.190\n",
      "[38, 271.7] loss: 0.015, acc: 0.092, f1: 0.172\n",
      "[39, 270.9] loss: 0.015, acc: 0.092, f1: 0.177\n",
      "[40, 269.3] loss: 0.015, acc: 0.103, f1: 0.194\n",
      "[41, 269.5] loss: 0.015, acc: 0.128, f1: 0.238\n",
      "[42, 269.9] loss: 0.014, acc: 0.130, f1: 0.237\n",
      "[43, 271.2] loss: 0.014, acc: 0.148, f1: 0.264\n",
      "[44, 270.6] loss: 0.014, acc: 0.148, f1: 0.265\n",
      "[45, 270.1] loss: 0.013, acc: 0.163, f1: 0.284\n",
      "[46, 269.0] loss: 0.013, acc: 0.180, f1: 0.313\n",
      "[47, 269.1] loss: 0.013, acc: 0.170, f1: 0.292\n",
      "[48, 269.4] loss: 0.012, acc: 0.216, f1: 0.350\n",
      "[49, 269.4] loss: 0.012, acc: 0.235, f1: 0.382\n",
      "[50, 269.7] loss: 0.012, acc: 0.220, f1: 0.364\n",
      "[51, 269.4] loss: 0.011, acc: 0.257, f1: 0.407\n",
      "[52, 269.6] loss: 0.011, acc: 0.281, f1: 0.437\n",
      "[53, 269.6] loss: 0.011, acc: 0.298, f1: 0.459\n",
      "[54, 269.9] loss: 0.011, acc: 0.275, f1: 0.427\n",
      "[55, 270.3] loss: 0.011, acc: 0.276, f1: 0.424\n",
      "[56, 270.6] loss: 0.010, acc: 0.321, f1: 0.485\n",
      "[57, 271.1] loss: 0.010, acc: 0.323, f1: 0.479\n",
      "[58, 269.7] loss: 0.010, acc: 0.323, f1: 0.481\n",
      "[59, 270.8] loss: 0.010, acc: 0.337, f1: 0.496\n",
      "[60, 270.0] loss: 0.009, acc: 0.359, f1: 0.517\n",
      "[61, 271.1] loss: 0.010, acc: 0.363, f1: 0.524\n",
      "[62, 270.6] loss: 0.009, acc: 0.374, f1: 0.537\n",
      "[63, 270.4] loss: 0.009, acc: 0.379, f1: 0.533\n",
      "[64, 269.9] loss: 0.009, acc: 0.390, f1: 0.556\n",
      "[65, 269.3] loss: 0.009, acc: 0.390, f1: 0.545\n",
      "[66, 269.8] loss: 0.008, acc: 0.442, f1: 0.599\n",
      "[67, 270.0] loss: 0.008, acc: 0.418, f1: 0.576\n",
      "[68, 269.0] loss: 0.008, acc: 0.415, f1: 0.566\n",
      "[69, 268.6] loss: 0.008, acc: 0.429, f1: 0.585\n",
      "[70, 269.7] loss: 0.008, acc: 0.412, f1: 0.570\n",
      "[71, 270.9] loss: 0.008, acc: 0.437, f1: 0.593\n",
      "[72, 271.8] loss: 0.007, acc: 0.442, f1: 0.595\n",
      "[73, 270.3] loss: 0.008, acc: 0.460, f1: 0.616\n",
      "[74, 270.8] loss: 0.007, acc: 0.441, f1: 0.595\n",
      "[75, 268.3] loss: 0.007, acc: 0.428, f1: 0.578\n",
      "[76, 269.1] loss: 0.007, acc: 0.459, f1: 0.611\n",
      "[77, 268.2] loss: 0.007, acc: 0.462, f1: 0.608\n",
      "[78, 268.5] loss: 0.007, acc: 0.468, f1: 0.617\n",
      "[79, 268.6] loss: 0.007, acc: 0.469, f1: 0.616\n",
      "[80, 269.1] loss: 0.007, acc: 0.480, f1: 0.633\n",
      "[81, 269.9] loss: 0.006, acc: 0.497, f1: 0.644\n",
      "[82, 269.8] loss: 0.006, acc: 0.472, f1: 0.626\n",
      "[83, 269.9] loss: 0.006, acc: 0.482, f1: 0.631\n",
      "[84, 269.6] loss: 0.006, acc: 0.487, f1: 0.625\n",
      "[85, 271.2] loss: 0.006, acc: 0.500, f1: 0.647\n",
      "[86, 270.5] loss: 0.006, acc: 0.495, f1: 0.643\n",
      "[87, 271.8] loss: 0.006, acc: 0.499, f1: 0.652\n",
      "[88, 270.3] loss: 0.006, acc: 0.475, f1: 0.623\n",
      "[89, 269.5] loss: 0.006, acc: 0.494, f1: 0.642\n",
      "[90, 269.1] loss: 0.006, acc: 0.479, f1: 0.634\n",
      "[91, 269.0] loss: 0.006, acc: 0.498, f1: 0.650\n",
      "[92, 269.9] loss: 0.005, acc: 0.519, f1: 0.658\n",
      "[93, 268.8] loss: 0.005, acc: 0.528, f1: 0.666\n",
      "[94, 269.8] loss: 0.005, acc: 0.522, f1: 0.663\n",
      "[95, 269.0] loss: 0.005, acc: 0.523, f1: 0.669\n",
      "[96, 270.2] loss: 0.005, acc: 0.509, f1: 0.647\n",
      "[97, 269.5] loss: 0.005, acc: 0.525, f1: 0.667\n",
      "[98, 270.1] loss: 0.006, acc: 0.520, f1: 0.661\n",
      "[99, 269.5] loss: 0.005, acc: 0.502, f1: 0.646\n",
      "[100, 268.6] loss: 0.005, acc: 0.512, f1: 0.656\n",
      "[101, 269.3] loss: 0.005, acc: 0.525, f1: 0.671\n",
      "[102, 269.1] loss: 0.005, acc: 0.538, f1: 0.675\n",
      "[103, 269.1] loss: 0.005, acc: 0.526, f1: 0.672\n",
      "[104, 269.0] loss: 0.005, acc: 0.535, f1: 0.673\n",
      "[105, 269.5] loss: 0.005, acc: 0.534, f1: 0.669\n",
      "[106, 269.9] loss: 0.004, acc: 0.529, f1: 0.666\n",
      "[107, 269.2] loss: 0.004, acc: 0.511, f1: 0.654\n",
      "[108, 267.5] loss: 0.005, acc: 0.536, f1: 0.676\n",
      "[109, 267.7] loss: 0.004, acc: 0.521, f1: 0.666\n",
      "[110, 270.8] loss: 0.004, acc: 0.548, f1: 0.690\n",
      "[111, 270.6] loss: 0.004, acc: 0.531, f1: 0.671\n",
      "[112, 270.1] loss: 0.004, acc: 0.536, f1: 0.676\n",
      "[113, 270.4] loss: 0.004, acc: 0.537, f1: 0.681\n",
      "[114, 269.6] loss: 0.004, acc: 0.549, f1: 0.679\n",
      "[115, 271.9] loss: 0.004, acc: 0.544, f1: 0.677\n",
      "[116, 270.5] loss: 0.004, acc: 0.558, f1: 0.686\n",
      "[117, 271.1] loss: 0.004, acc: 0.544, f1: 0.682\n",
      "[118, 272.4] loss: 0.004, acc: 0.555, f1: 0.688\n",
      "[119, 270.4] loss: 0.004, acc: 0.570, f1: 0.700\n",
      "[120, 270.5] loss: 0.004, acc: 0.550, f1: 0.681\n",
      "[121, 270.0] loss: 0.004, acc: 0.535, f1: 0.675\n",
      "[122, 270.3] loss: 0.004, acc: 0.539, f1: 0.682\n",
      "[123, 271.0] loss: 0.004, acc: 0.544, f1: 0.679\n",
      "[124, 269.3] loss: 0.004, acc: 0.553, f1: 0.687\n",
      "[125, 270.5] loss: 0.003, acc: 0.556, f1: 0.690\n",
      "[126, 269.7] loss: 0.004, acc: 0.558, f1: 0.688\n",
      "[127, 270.6] loss: 0.004, acc: 0.557, f1: 0.686\n",
      "[128, 270.7] loss: 0.003, acc: 0.556, f1: 0.697\n",
      "[129, 269.9] loss: 0.004, acc: 0.552, f1: 0.686\n",
      "[130, 269.6] loss: 0.003, acc: 0.560, f1: 0.693\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(130):\n",
    "    t0 = time.time()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        model.train()\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % len(train_dl) == len(train_dl)-1:\n",
    "            model.eval();\n",
    "            preds = []\n",
    "            targs = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data in valid_dl:\n",
    "                    inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                    outputs = model(inputs)\n",
    "                    preds.append(outputs.cpu().detach())\n",
    "                    targs.append(labels.cpu().detach())\n",
    "\n",
    "                preds = torch.cat(preds)\n",
    "                targs = torch.cat(targs)\n",
    "            \n",
    "            accuracy = accuracy_score(preds.sigmoid() > 0.5, targs)\n",
    "            f1 = f1_score(preds.sigmoid() > 0.5, targs, average='micro')\n",
    "            print(f'[{epoch + 1}, {time.time() - t0:.1f}] loss: {running_loss / (len(train_dl)-1):.3f}, acc: {accuracy:.3f}, f1: {f1:.3f}')\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            if (epoch % 10 == 0) and (epoch != 0): torch.save(model.state_dict(), f'models/{epoch}_lmepool_{round(f1, 2)}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "f1s = []\n",
    "ts = []\n",
    "for t in np.linspace(0.4, 1, 61):\n",
    "    f1s.append(f1_score(preds.sigmoid() > t, targs, average='micro'))\n",
    "    ts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6946884148891677"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48000000000000004"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[np.argmax(f1s)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
