{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdcall.data import *\n",
    "from birdcall.metrics import *\n",
    "from birdcall.ops import *\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 16\n",
    "MAX_LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_pickle('data/classes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = pd.read_pickle('data/all_splits.pkl')\n",
    "all_train_items = pd.read_pickle('data/all_train_items.pkl')\n",
    "\n",
    "train_items = np.array(all_train_items)[splits[0][0]].tolist()\n",
    "val_items = np.array(all_train_items)[splits[0][1]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class2train_items = defaultdict(list)\n",
    "\n",
    "for cls_name, path, duration in train_items:\n",
    "    class2train_items[cls_name].append((path, duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MelspecPoolDataset(class2train_items, classes, len_mult=50, normalize=False)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=BS, num_workers=NUM_WORKERS, pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_items = [(classes.index(item[0]), item[1], item[2]) for item in val_items]\n",
    "val_items_binned = bin_items_negative_class(val_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(*list(torchvision.models.resnet34(True).children())[:-2])\n",
    "        self.classifier = nn.Sequential(*[\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, len(classes))\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.log10(1 + x)\n",
    "        max_per_example = x.view(x.shape[0], -1).max(1)[0] # scaling to between 0 and 1\n",
    "        x /= max_per_example[:, None, None, None, None]     # per example!\n",
    "        bs, im_num = x.shape[:2]\n",
    "        x = x.view(-1, x.shape[2], x.shape[3], x.shape[4])\n",
    "        x = self.cnn(x)\n",
    "        x = x.mean((2,3))\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(bs, im_num, -1)\n",
    "        x = lme_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_ds = SoundscapeMelspecPoolDataset(pd.read_pickle('data/soundscape_items.pkl'), classes)\n",
    "sc_dl = torch.utils.data.DataLoader(sc_ds, batch_size=2*BS, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 19.5] loss: 0.023, f1: 0.000, sc_f1: 0.000\n",
      "[10, 38.3] loss: 0.019, f1: 0.018, sc_f1: 0.000\n",
      "[15, 56.7] loss: 0.016, f1: 0.115, sc_f1: 0.000\n",
      "[20, 74.9] loss: 0.013, f1: 0.342, sc_f1: 0.012\n",
      "[25, 94.1] loss: 0.011, f1: 0.472, sc_f1: 0.000\n",
      "[30, 113.0] loss: 0.009, f1: 0.562, sc_f1: 0.011\n",
      "[35, 131.8] loss: 0.008, f1: 0.616, sc_f1: 0.024\n",
      "[40, 150.2] loss: 0.007, f1: 0.637, sc_f1: 0.023\n",
      "[45, 168.6] loss: 0.006, f1: 0.658, sc_f1: 0.022\n",
      "[50, 187.9] loss: 0.005, f1: 0.668, sc_f1: 0.010\n",
      "[55, 206.6] loss: 0.005, f1: 0.682, sc_f1: 0.032\n",
      "[60, 224.8] loss: 0.004, f1: 0.690, sc_f1: 0.012\n",
      "[65, 243.1] loss: 0.004, f1: 0.700, sc_f1: 0.011\n",
      "[70, 261.5] loss: 0.003, f1: 0.704, sc_f1: 0.012\n",
      "[75, 280.2] loss: 0.003, f1: 0.706, sc_f1: 0.000\n",
      "[80, 299.0] loss: 0.003, f1: 0.707, sc_f1: 0.000\n",
      "[85, 317.9] loss: 0.003, f1: 0.708, sc_f1: 0.010\n",
      "[90, 336.7] loss: 0.002, f1: 0.708, sc_f1: 0.021\n",
      "[95, 355.8] loss: 0.003, f1: 0.708, sc_f1: 0.012\n",
      "[100, 374.6] loss: 0.002, f1: 0.702, sc_f1: 0.011\n",
      "[105, 392.9] loss: 0.002, f1: 0.700, sc_f1: 0.011\n",
      "[110, 411.6] loss: 0.002, f1: 0.698, sc_f1: 0.000\n",
      "[115, 430.7] loss: 0.002, f1: 0.706, sc_f1: 0.011\n",
      "[120, 449.5] loss: 0.002, f1: 0.712, sc_f1: 0.012\n",
      "[125, 468.1] loss: 0.002, f1: 0.710, sc_f1: 0.011\n",
      "[130, 487.2] loss: 0.002, f1: 0.713, sc_f1: 0.011\n",
      "[135, 506.0] loss: 0.002, f1: 0.713, sc_f1: 0.011\n",
      "[140, 524.7] loss: 0.001, f1: 0.720, sc_f1: 0.000\n",
      "[145, 543.3] loss: 0.001, f1: 0.710, sc_f1: 0.000\n",
      "[150, 562.6] loss: 0.001, f1: 0.718, sc_f1: 0.000\n",
      "[155, 581.6] loss: 0.001, f1: 0.724, sc_f1: 0.000\n",
      "[160, 600.4] loss: 0.001, f1: 0.712, sc_f1: 0.011\n",
      "[165, 619.0] loss: 0.001, f1: 0.723, sc_f1: 0.022\n",
      "[170, 638.0] loss: 0.001, f1: 0.715, sc_f1: 0.011\n",
      "[175, 657.1] loss: 0.001, f1: 0.734, sc_f1: 0.012\n",
      "[180, 675.4] loss: 0.001, f1: 0.724, sc_f1: 0.000\n",
      "[185, 694.5] loss: 0.001, f1: 0.726, sc_f1: 0.000\n",
      "[190, 713.6] loss: 0.001, f1: 0.725, sc_f1: 0.012\n",
      "[195, 732.3] loss: 0.001, f1: 0.724, sc_f1: 0.000\n",
      "[200, 750.7] loss: 0.001, f1: 0.725, sc_f1: 0.000\n",
      "[205, 769.4] loss: 0.001, f1: 0.725, sc_f1: 0.000\n",
      "[210, 787.6] loss: 0.001, f1: 0.715, sc_f1: 0.000\n",
      "[215, 806.6] loss: 0.001, f1: 0.727, sc_f1: 0.000\n",
      "[220, 825.4] loss: 0.001, f1: 0.732, sc_f1: 0.000\n",
      "[225, 844.6] loss: 0.001, f1: 0.723, sc_f1: 0.000\n",
      "[230, 863.2] loss: 0.001, f1: 0.728, sc_f1: 0.000\n",
      "[235, 881.8] loss: 0.001, f1: 0.736, sc_f1: 0.000\n",
      "[240, 901.0] loss: 0.001, f1: 0.719, sc_f1: 0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3950528cd74b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'!!! nan encountered in loss !!! epoch: {epoch}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for epoch in range(260):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        model.train()\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if np.isnan(loss.item()): \n",
    "            raise Exception(f'!!! nan encountered in loss !!! epoch: {epoch}\\n')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "    if epoch % 5 == 4:\n",
    "        model.eval();\n",
    "        preds = []\n",
    "        targs = []\n",
    "\n",
    "        for num_specs in val_items_binned.keys():\n",
    "            valid_ds = MelspecShortishValidatioDataset(val_items_binned[num_specs], classes)\n",
    "            valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=2*BS, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data in valid_dl:\n",
    "                    inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                    outputs = model(inputs)\n",
    "                    preds.append(outputs.cpu().detach())\n",
    "                    targs.append(labels.cpu().detach())\n",
    "\n",
    "        preds = torch.cat(preds)\n",
    "        targs = torch.cat(targs)\n",
    "\n",
    "        f1s = []\n",
    "        ts = []\n",
    "        for t in np.linspace(0.4, 1, 61):\n",
    "            f1s.append(f1_score(preds.sigmoid() > t, targs, average='micro'))\n",
    "            ts.append(t)\n",
    "        \n",
    "        sc_preds = []\n",
    "        sc_targs = []\n",
    "        with torch.no_grad():\n",
    "            for data in sc_dl:\n",
    "                inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                outputs = model(inputs)\n",
    "                sc_preds.append(outputs.cpu().detach())\n",
    "                sc_targs.append(labels.cpu().detach())\n",
    "\n",
    "        sc_preds = torch.cat(sc_preds)\n",
    "        sc_targs = torch.cat(sc_targs)\n",
    "        sc_f1 = f1_score(sc_preds.sigmoid() > 0.5, sc_targs, average='micro')\n",
    "        \n",
    "        sc_f1s = []\n",
    "        sc_ts = []\n",
    "        for t in np.linspace(0.4, 1, 61):\n",
    "            sc_f1s.append(f1_score(sc_preds.sigmoid() > t, sc_targs, average='micro'))\n",
    "            sc_ts.append(t)\n",
    "        \n",
    "        f1 = f1_score(preds.sigmoid() > 0.5, targs, average='micro')\n",
    "        print(f'[{epoch + 1}, {(time.time() - t0)/60:.1f}] loss: {running_loss / (len(train_dl)-1):.3f}, f1: {max(f1s):.3f}, sc_f1: {max(sc_f1s):.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "        torch.save(model.state_dict(), f'models/{epoch+1}_lmepool_simple_minmax_log_{round(f1, 2)}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
