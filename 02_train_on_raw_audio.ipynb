{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let us get all the data that we need. Through the magic of `nbdev`, we will use the functionality we defined in `01_gettin_started`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdcall.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5280, 2640)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 128\n",
    "\n",
    "dls = DataLoaders(\n",
    "    DataLoader(dataset=train_ds, bs=BS, num_workers=NUM_WORKERS, shuffle=True),\n",
    "    DataLoader(dataset=valid_ds, bs=BS, num_workers=NUM_WORKERS)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 160000]), torch.Size([128, 264]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.train.one_batch()\n",
    "b[0].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0018, device='cuda:0'), tensor(1.3341, device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].mean(), b[0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some sort of architecture to get started - the one adapted from this [paper](https://www.groundai.com/project/end-to-end-environmental-sound-classification-using-a-1d-convolutional-neural-network/1) seems like a good place to start. Bear in mind though that it was designed with considering the entire recording and with environment classification in mind - it's performance on a task like that at hand might be subpaar. Revisiting the architecture at a later time might be a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_arch = lambda: nn.Sequential(*[\n",
    "    Lambda(lambda x: x.unsqueeze(1)),\n",
    "    ConvLayer(1, 16, ks=64, stride=2, ndim=1),\n",
    "    ConvLayer(16, 16, ks=8, stride=8, ndim=1),\n",
    "    ConvLayer(16, 32, ks=32, stride=2, ndim=1),\n",
    "    ConvLayer(32, 32, ks=8, stride=8, ndim=1),\n",
    "    ConvLayer(32, 64, ks=16, stride=2, ndim=1),\n",
    "    ConvLayer(64, 128, ks=8, stride=2, ndim=1),\n",
    "    ConvLayer(128, 256, ks=4, stride=2, ndim=1),\n",
    "    ConvLayer(256, 256, ks=4, stride=4, ndim=1),\n",
    "    Flatten(),\n",
    "    LinBnDrop(5120, 512, p=0.25, act=nn.ReLU()),\n",
    "    LinBnDrop(512, 512, p=0.25, act=nn.ReLU()),\n",
    "    LinBnDrop(512, 256, p=0.25, act=nn.ReLU()),\n",
    "    LinBnDrop(256, len(classes)),\n",
    "    nn.Sigmoid()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of functions to help us calculate metrics for diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def preds_to_tp_fp_fn(preds, targs):\n",
    "    positives = preds > 0.5\n",
    "    true_positives = positives[targs == 1]\n",
    "    false_positives = positives[targs != 1]\n",
    "    negatives = ~positives\n",
    "    false_negatives = negatives[targs == 1]\n",
    "    return true_positives.sum(), false_positives.sum(), false_negatives.sum()\n",
    "\n",
    "def precision(preds, targs):\n",
    "    tp, fp, fn = preds_to_tp_fp_fn(preds, targs)\n",
    "    return (tp.float() / (tp + fp)).item()\n",
    "\n",
    "def recall(preds, targs):\n",
    "    tp, fp, fn = preds_to_tp_fp_fn(preds, targs)\n",
    "    return (tp.float() / (tp + fn)).item()\n",
    "\n",
    "def f1(preds, targs, eps=1e-8):\n",
    "    prec = precision(preds, targs)\n",
    "    rec = recall(preds, targs)\n",
    "    return 2 * (prec * rec) / (prec + rec + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dls,\n",
    "    get_arch(),\n",
    "    metrics=[AccumMetric(precision), AccumMetric(recall), AccumMetric(f1)],\n",
    "    loss_func=BCELossFlat()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.668979</td>\n",
       "      <td>0.592719</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.466117</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.241570</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>0.035940</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.070555</td>\n",
       "      <td>0.029092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.045886</td>\n",
       "      <td>0.027578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034517</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>0.025046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.026782</td>\n",
       "      <td>0.024864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.025567</td>\n",
       "      <td>0.024558</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.024988</td>\n",
       "      <td>0.024467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.024681</td>\n",
       "      <td>0.024603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.024535</td>\n",
       "      <td>0.024184</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.024364</td>\n",
       "      <td>0.024232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.024276</td>\n",
       "      <td>0.024230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.024207</td>\n",
       "      <td>0.024195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.024145</td>\n",
       "      <td>0.024102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.024043</td>\n",
       "      <td>0.023873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.023990</td>\n",
       "      <td>0.023768</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.023902</td>\n",
       "      <td>0.024197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.023796</td>\n",
       "      <td>0.023771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.023990</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.023653</td>\n",
       "      <td>0.023371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.023596</td>\n",
       "      <td>0.023698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.023485</td>\n",
       "      <td>0.023292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.023412</td>\n",
       "      <td>0.023301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.023337</td>\n",
       "      <td>0.023326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.023183</td>\n",
       "      <td>0.022995</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.023113</td>\n",
       "      <td>0.023047</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.023019</td>\n",
       "      <td>0.023375</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(30, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't look great! Maybe we have a bug somewhere in the training, maybe our code for caclulating metrics is bugged. It might also be that it will be very hard to learn from raw audio or that our architecture and the task are mismatched.\n",
    "\n",
    "I would guess the issue lies somwhere between training on raw audio and the architecture choice. Nonetheless, this will not stop us! The first order of business is to create an end to end pipeline, all the way to successful submission. Once we have this in place, we will be in a good position to start fiddling with making improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir data/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learn.model.state_dict(), 'data/models/first_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
