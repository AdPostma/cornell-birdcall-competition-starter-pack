{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdcall.data import *\n",
    "from birdcall.metrics import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_pickle('data/classes.pkl')\n",
    "train_ds = MelspecPoolDataset(pd.read_pickle('data/train_set.pkl'), classes, len_mult=30)\n",
    "valid_ds = MelspecPoolDataset(pd.read_pickle('data/val_set.pkl'), classes, len_mult=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 1320)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=NUM_WORKERS)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=2*16, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 10, 3, 80, 212]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for b in train_dl: break\n",
    "b[0].shape, b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2136), tensor(1.6780))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].mean(), b[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(*list(torchvision.models.resnet34(True).children())[:-2])\n",
    "        self.classifier = nn.Sequential(*[\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(p=0.5), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, len(classes))\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs, im_num, ch, y_dim, x_dim = x.shape\n",
    "        x = self.cnn(x.view(-1, ch, y_dim, x_dim))\n",
    "        x = x.mean((2,3))\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(bs, im_num, -1)\n",
    "        x = x.mean(-2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 143.8] loss: 0.146, acc: 0.000, f1: 0.005\n",
      "[2, 139.4] loss: 0.025, acc: 0.000, f1: 0.015\n",
      "[3, 139.4] loss: 0.025, acc: 0.000, f1: 0.004\n",
      "[4, 140.3] loss: 0.025, acc: 0.000, f1: 0.006\n",
      "[5, 138.3] loss: 0.025, acc: 0.000, f1: 0.024\n",
      "[6, 140.3] loss: 0.024, acc: 0.000, f1: 0.010\n",
      "[7, 139.1] loss: 0.023, acc: 0.000, f1: 0.022\n",
      "[8, 140.5] loss: 0.023, acc: 0.002, f1: 0.017\n",
      "[9, 139.7] loss: 0.022, acc: 0.000, f1: 0.007\n",
      "[10, 138.9] loss: 0.022, acc: 0.000, f1: 0.021\n",
      "[11, 139.2] loss: 0.021, acc: 0.001, f1: 0.024\n",
      "[12, 138.7] loss: 0.021, acc: 0.000, f1: 0.008\n",
      "[13, 140.9] loss: 0.021, acc: 0.004, f1: 0.026\n",
      "[14, 140.4] loss: 0.020, acc: 0.005, f1: 0.025\n",
      "[15, 138.7] loss: 0.020, acc: 0.008, f1: 0.029\n",
      "[16, 140.1] loss: 0.020, acc: 0.008, f1: 0.029\n",
      "[17, 140.3] loss: 0.019, acc: 0.011, f1: 0.045\n",
      "[19, 140.1] loss: 0.018, acc: 0.036, f1: 0.118\n",
      "[20, 139.5] loss: 0.018, acc: 0.039, f1: 0.038\n",
      "[21, 386.1] loss: 0.018, acc: 0.062, f1: 0.043\n",
      "[22, 139.2] loss: 0.017, acc: 0.035, f1: 0.013\n",
      "[23, 139.7] loss: 0.017, acc: 0.059, f1: 0.181\n",
      "[24, 140.7] loss: 0.017, acc: 0.080, f1: 0.208\n",
      "[25, 138.7] loss: 0.016, acc: 0.067, f1: 0.219\n",
      "[26, 140.4] loss: 0.016, acc: 0.100, f1: 0.254\n",
      "[27, 141.0] loss: 0.016, acc: 0.096, f1: 0.249\n",
      "[28, 140.5] loss: 0.015, acc: 0.100, f1: 0.261\n",
      "[29, 140.3] loss: 0.015, acc: 0.112, f1: 0.251\n",
      "[30, 140.9] loss: 0.015, acc: 0.081, f1: 0.224\n",
      "[31, 139.6] loss: 0.014, acc: 0.125, f1: 0.262\n",
      "[32, 139.1] loss: 0.014, acc: 0.128, f1: 0.207\n",
      "[33, 139.9] loss: 0.014, acc: 0.133, f1: 0.304\n",
      "[34, 139.7] loss: 0.014, acc: 0.152, f1: 0.331\n",
      "[35, 140.6] loss: 0.013, acc: 0.135, f1: 0.311\n",
      "[36, 141.6] loss: 0.013, acc: 0.160, f1: 0.353\n",
      "[37, 142.0] loss: 0.013, acc: 0.141, f1: 0.316\n",
      "[38, 141.6] loss: 0.013, acc: 0.183, f1: 0.380\n",
      "[39, 139.3] loss: 0.013, acc: 0.195, f1: 0.377\n",
      "[40, 139.8] loss: 0.012, acc: 0.191, f1: 0.401\n",
      "[41, 385.7] loss: 0.012, acc: 0.192, f1: 0.399\n",
      "[42, 140.1] loss: 0.012, acc: 0.214, f1: 0.420\n",
      "[43, 140.4] loss: 0.012, acc: 0.233, f1: 0.437\n",
      "[44, 140.0] loss: 0.011, acc: 0.219, f1: 0.285\n",
      "[45, 140.8] loss: 0.011, acc: 0.220, f1: 0.431\n",
      "[46, 140.9] loss: 0.011, acc: 0.235, f1: 0.426\n",
      "[47, 141.0] loss: 0.011, acc: 0.242, f1: 0.443\n",
      "[48, 139.2] loss: 0.011, acc: 0.252, f1: 0.427\n",
      "[49, 141.5] loss: 0.010, acc: 0.281, f1: 0.437\n",
      "[50, 139.5] loss: 0.010, acc: 0.257, f1: 0.417\n",
      "[51, 140.0] loss: 0.010, acc: 0.271, f1: 0.459\n",
      "[52, 139.6] loss: 0.010, acc: 0.288, f1: 0.490\n",
      "[53, 140.6] loss: 0.010, acc: 0.292, f1: 0.485\n",
      "[54, 140.1] loss: 0.010, acc: 0.299, f1: 0.499\n",
      "[55, 139.9] loss: 0.009, acc: 0.269, f1: 0.457\n",
      "[56, 140.9] loss: 0.009, acc: 0.336, f1: 0.498\n",
      "[57, 142.3] loss: 0.009, acc: 0.310, f1: 0.504\n",
      "[58, 140.6] loss: 0.009, acc: 0.315, f1: 0.514\n",
      "[59, 140.1] loss: 0.009, acc: 0.333, f1: 0.523\n",
      "[60, 140.7] loss: 0.008, acc: 0.344, f1: 0.534\n",
      "[61, 385.4] loss: 0.008, acc: 0.336, f1: 0.545\n",
      "[62, 139.0] loss: 0.008, acc: 0.341, f1: 0.541\n",
      "[63, 139.3] loss: 0.008, acc: 0.335, f1: 0.542\n",
      "[64, 139.3] loss: 0.008, acc: 0.348, f1: 0.547\n",
      "[65, 142.1] loss: 0.008, acc: 0.333, f1: 0.540\n",
      "[66, 140.6] loss: 0.007, acc: 0.303, f1: 0.478\n",
      "[67, 140.3] loss: 0.007, acc: 0.366, f1: 0.561\n",
      "[68, 140.0] loss: 0.007, acc: 0.379, f1: 0.570\n",
      "[69, 141.4] loss: 0.007, acc: 0.357, f1: 0.554\n",
      "[70, 140.2] loss: 0.007, acc: 0.373, f1: 0.564\n",
      "[71, 139.3] loss: 0.007, acc: 0.358, f1: 0.547\n",
      "[72, 139.3] loss: 0.007, acc: 0.388, f1: 0.568\n",
      "[73, 140.3] loss: 0.007, acc: 0.392, f1: 0.579\n",
      "[74, 139.8] loss: 0.007, acc: 0.388, f1: 0.578\n",
      "[75, 139.9] loss: 0.006, acc: 0.390, f1: 0.561\n",
      "[76, 140.5] loss: 0.006, acc: 0.405, f1: 0.583\n",
      "[77, 139.6] loss: 0.006, acc: 0.402, f1: 0.583\n",
      "[78, 139.4] loss: 0.006, acc: 0.404, f1: 0.583\n",
      "[79, 141.0] loss: 0.006, acc: 0.411, f1: 0.581\n",
      "[80, 140.3] loss: 0.006, acc: 0.400, f1: 0.586\n",
      "[81, 387.7] loss: 0.006, acc: 0.395, f1: 0.583\n",
      "[82, 140.0] loss: 0.006, acc: 0.414, f1: 0.590\n",
      "[83, 140.0] loss: 0.006, acc: 0.402, f1: 0.586\n",
      "[84, 139.9] loss: 0.006, acc: 0.401, f1: 0.578\n",
      "[85, 139.1] loss: 0.006, acc: 0.432, f1: 0.612\n",
      "[86, 139.5] loss: 0.005, acc: 0.444, f1: 0.604\n",
      "[87, 139.8] loss: 0.005, acc: 0.423, f1: 0.606\n",
      "[88, 139.9] loss: 0.005, acc: 0.461, f1: 0.624\n",
      "[89, 140.3] loss: 0.005, acc: 0.417, f1: 0.596\n",
      "[90, 139.8] loss: 0.005, acc: 0.411, f1: 0.583\n",
      "[91, 141.0] loss: 0.005, acc: 0.436, f1: 0.603\n",
      "[92, 141.8] loss: 0.005, acc: 0.430, f1: 0.593\n",
      "[93, 140.1] loss: 0.005, acc: 0.442, f1: 0.608\n",
      "[94, 139.9] loss: 0.005, acc: 0.402, f1: 0.582\n",
      "[95, 140.2] loss: 0.005, acc: 0.436, f1: 0.598\n",
      "[96, 140.1] loss: 0.005, acc: 0.437, f1: 0.606\n",
      "[97, 141.0] loss: 0.005, acc: 0.410, f1: 0.559\n",
      "[98, 141.1] loss: 0.005, acc: 0.444, f1: 0.598\n",
      "[99, 140.2] loss: 0.005, acc: 0.448, f1: 0.615\n",
      "[100, 141.9] loss: 0.004, acc: 0.452, f1: 0.610\n",
      "[101, 388.0] loss: 0.004, acc: 0.458, f1: 0.607\n",
      "[102, 138.8] loss: 0.004, acc: 0.438, f1: 0.610\n",
      "[103, 139.4] loss: 0.004, acc: 0.467, f1: 0.605\n",
      "[104, 139.8] loss: 0.004, acc: 0.473, f1: 0.626\n",
      "[105, 139.3] loss: 0.004, acc: 0.460, f1: 0.608\n",
      "[106, 139.5] loss: 0.004, acc: 0.461, f1: 0.610\n",
      "[107, 139.9] loss: 0.004, acc: 0.448, f1: 0.613\n",
      "[108, 139.5] loss: 0.004, acc: 0.474, f1: 0.630\n",
      "[109, 139.2] loss: 0.004, acc: 0.482, f1: 0.640\n",
      "[110, 138.3] loss: 0.004, acc: 0.482, f1: 0.642\n",
      "[111, 138.7] loss: 0.004, acc: 0.434, f1: 0.599\n",
      "[112, 139.1] loss: 0.004, acc: 0.457, f1: 0.620\n",
      "[113, 138.8] loss: 0.004, acc: 0.455, f1: 0.612\n",
      "[114, 139.4] loss: 0.004, acc: 0.477, f1: 0.634\n",
      "[115, 139.7] loss: 0.004, acc: 0.495, f1: 0.633\n",
      "[116, 141.0] loss: 0.003, acc: 0.489, f1: 0.626\n",
      "[117, 140.8] loss: 0.004, acc: 0.447, f1: 0.603\n",
      "[118, 139.4] loss: 0.004, acc: 0.452, f1: 0.617\n",
      "[119, 139.6] loss: 0.004, acc: 0.466, f1: 0.612\n",
      "[120, 140.1] loss: 0.003, acc: 0.501, f1: 0.632\n",
      "[121, 384.8] loss: 0.003, acc: 0.477, f1: 0.628\n",
      "[122, 139.1] loss: 0.003, acc: 0.474, f1: 0.626\n",
      "[123, 139.9] loss: 0.004, acc: 0.487, f1: 0.623\n",
      "[124, 140.1] loss: 0.003, acc: 0.483, f1: 0.623\n",
      "[125, 141.3] loss: 0.003, acc: 0.455, f1: 0.600\n",
      "[126, 140.1] loss: 0.004, acc: 0.452, f1: 0.614\n",
      "[127, 140.3] loss: 0.003, acc: 0.452, f1: 0.612\n",
      "[128, 140.7] loss: 0.005, acc: 0.464, f1: 0.624\n",
      "[129, 141.1] loss: 0.003, acc: 0.473, f1: 0.623\n",
      "[130, 140.7] loss: 0.003, acc: 0.486, f1: 0.628\n",
      "[131, 140.4] loss: 0.003, acc: 0.477, f1: 0.627\n",
      "[132, 140.4] loss: 0.003, acc: 0.470, f1: 0.622\n",
      "[133, 139.9] loss: 0.003, acc: 0.456, f1: 0.610\n",
      "[134, 140.1] loss: 0.003, acc: 0.458, f1: 0.617\n",
      "[135, 140.4] loss: 0.003, acc: 0.462, f1: 0.616\n",
      "[136, 140.6] loss: 0.003, acc: 0.517, f1: 0.643\n",
      "[137, 140.7] loss: 0.003, acc: 0.502, f1: 0.639\n",
      "[138, 140.0] loss: 0.003, acc: 0.436, f1: 0.599\n",
      "[139, 139.3] loss: 0.003, acc: 0.489, f1: 0.640\n",
      "[140, 139.6] loss: 0.003, acc: 0.492, f1: 0.635\n",
      "[141, 387.4] loss: 0.003, acc: 0.504, f1: 0.634\n",
      "[142, 140.2] loss: 0.003, acc: 0.441, f1: 0.597\n",
      "[143, 140.7] loss: 0.003, acc: 0.457, f1: 0.612\n",
      "[144, 139.7] loss: 0.003, acc: 0.486, f1: 0.619\n",
      "[146, 140.1] loss: 0.003, acc: 0.473, f1: 0.613\n",
      "[147, 139.9] loss: 0.003, acc: 0.508, f1: 0.650\n",
      "[148, 141.0] loss: 0.003, acc: 0.494, f1: 0.633\n",
      "[149, 139.7] loss: 0.003, acc: 0.465, f1: 0.610\n",
      "[150, 140.1] loss: 0.003, acc: 0.485, f1: 0.631\n",
      "[151, 140.5] loss: 0.003, acc: 0.482, f1: 0.615\n",
      "[152, 140.1] loss: 0.003, acc: 0.498, f1: 0.634\n",
      "[153, 140.1] loss: 0.002, acc: 0.475, f1: 0.617\n",
      "[154, 140.1] loss: 0.002, acc: 0.482, f1: 0.622\n",
      "[155, 141.0] loss: 0.002, acc: 0.498, f1: 0.633\n",
      "[156, 139.4] loss: 0.002, acc: 0.487, f1: 0.639\n",
      "[157, 141.4] loss: 0.003, acc: 0.477, f1: 0.628\n",
      "[158, 142.5] loss: 0.002, acc: 0.463, f1: 0.606\n",
      "[159, 140.7] loss: 0.002, acc: 0.454, f1: 0.603\n",
      "[160, 140.0] loss: 0.002, acc: 0.487, f1: 0.626\n",
      "[161, 388.0] loss: 0.002, acc: 0.490, f1: 0.621\n",
      "[162, 140.2] loss: 0.002, acc: 0.473, f1: 0.601\n",
      "[163, 140.1] loss: 0.002, acc: 0.479, f1: 0.616\n",
      "[164, 139.8] loss: 0.002, acc: 0.477, f1: 0.617\n",
      "[165, 140.7] loss: 0.002, acc: 0.467, f1: 0.613\n",
      "[166, 140.0] loss: 0.003, acc: 0.490, f1: 0.620\n",
      "[167, 139.9] loss: 0.002, acc: 0.492, f1: 0.634\n",
      "[168, 140.9] loss: 0.002, acc: 0.505, f1: 0.634\n",
      "[169, 140.4] loss: 0.002, acc: 0.481, f1: 0.608\n",
      "[170, 139.6] loss: 0.002, acc: 0.497, f1: 0.635\n",
      "[171, 140.3] loss: 0.002, acc: 0.477, f1: 0.612\n",
      "[172, 140.5] loss: 0.002, acc: 0.481, f1: 0.618\n",
      "[173, 140.8] loss: 0.002, acc: 0.503, f1: 0.636\n",
      "[174, 139.3] loss: 0.002, acc: 0.487, f1: 0.618\n",
      "[175, 140.5] loss: 0.002, acc: 0.498, f1: 0.631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176, 139.9] loss: 0.002, acc: 0.470, f1: 0.604\n",
      "[177, 139.5] loss: 0.002, acc: 0.506, f1: 0.629\n",
      "[178, 140.7] loss: 0.002, acc: 0.486, f1: 0.623\n",
      "[179, 141.0] loss: 0.002, acc: 0.520, f1: 0.643\n",
      "[180, 141.2] loss: 0.002, acc: 0.496, f1: 0.625\n",
      "[181, 386.7] loss: 0.002, acc: 0.528, f1: 0.646\n",
      "[182, 140.1] loss: 0.002, acc: 0.500, f1: 0.624\n",
      "[183, 139.9] loss: 0.002, acc: 0.478, f1: 0.608\n",
      "[184, 139.7] loss: 0.002, acc: 0.492, f1: 0.619\n",
      "[185, 139.9] loss: 0.002, acc: 0.505, f1: 0.635\n",
      "[186, 141.0] loss: 0.002, acc: 0.492, f1: 0.616\n",
      "[187, 141.5] loss: 0.002, acc: 0.461, f1: 0.614\n",
      "[188, 140.7] loss: 0.002, acc: 0.516, f1: 0.630\n",
      "[189, 140.1] loss: 0.002, acc: 0.502, f1: 0.626\n",
      "[190, 139.5] loss: 0.002, acc: 0.502, f1: 0.615\n",
      "[191, 140.0] loss: 0.002, acc: 0.523, f1: 0.646\n",
      "[192, 140.2] loss: 0.002, acc: 0.488, f1: 0.610\n",
      "[193, 140.5] loss: 0.002, acc: 0.504, f1: 0.639\n",
      "[194, 141.1] loss: 0.002, acc: 0.492, f1: 0.629\n",
      "[195, 140.6] loss: 0.002, acc: 0.492, f1: 0.612\n",
      "[196, 141.6] loss: 0.002, acc: 0.524, f1: 0.652\n",
      "[197, 141.5] loss: 0.002, acc: 0.536, f1: 0.652\n",
      "[198, 140.1] loss: 0.002, acc: 0.508, f1: 0.635\n",
      "[199, 140.4] loss: 0.002, acc: 0.533, f1: 0.649\n",
      "[200, 140.6] loss: 0.002, acc: 0.520, f1: 0.627\n",
      "[201, 374.3] loss: 0.001, acc: 0.511, f1: 0.626\n",
      "[202, 139.8] loss: 0.002, acc: 0.516, f1: 0.634\n",
      "[203, 141.0] loss: 0.001, acc: 0.520, f1: 0.643\n",
      "[204, 141.3] loss: 0.002, acc: 0.521, f1: 0.612\n",
      "[205, 140.2] loss: 0.002, acc: 0.515, f1: 0.643\n",
      "[206, 140.1] loss: 0.001, acc: 0.491, f1: 0.621\n",
      "[207, 140.6] loss: 0.001, acc: 0.486, f1: 0.607\n",
      "[208, 140.3] loss: 0.002, acc: 0.528, f1: 0.636\n",
      "[209, 141.2] loss: 0.002, acc: 0.472, f1: 0.603\n",
      "[210, 140.0] loss: 0.002, acc: 0.508, f1: 0.642\n",
      "[211, 139.9] loss: 0.002, acc: 0.453, f1: 0.596\n",
      "[212, 140.4] loss: 0.001, acc: 0.525, f1: 0.648\n",
      "[213, 142.0] loss: 0.002, acc: 0.502, f1: 0.633\n",
      "[214, 140.4] loss: 0.002, acc: 0.495, f1: 0.619\n",
      "[215, 139.1] loss: 0.002, acc: 0.507, f1: 0.641\n",
      "[216, 140.3] loss: 0.002, acc: 0.479, f1: 0.621\n",
      "[217, 139.6] loss: 0.002, acc: 0.523, f1: 0.642\n",
      "[218, 139.3] loss: 0.002, acc: 0.467, f1: 0.602\n",
      "[219, 140.3] loss: 0.001, acc: 0.508, f1: 0.627\n",
      "[220, 141.3] loss: 0.001, acc: 0.533, f1: 0.653\n",
      "[221, 385.7] loss: 0.001, acc: 0.476, f1: 0.617\n",
      "[222, 139.4] loss: 0.002, acc: 0.490, f1: 0.616\n",
      "[223, 140.4] loss: 0.001, acc: 0.496, f1: 0.620\n",
      "[224, 138.8] loss: 0.001, acc: 0.525, f1: 0.645\n",
      "[225, 139.6] loss: 0.002, acc: 0.511, f1: 0.628\n",
      "[226, 140.2] loss: 0.001, acc: 0.510, f1: 0.639\n",
      "[227, 140.5] loss: 0.002, acc: 0.486, f1: 0.609\n",
      "[228, 139.2] loss: 0.002, acc: 0.509, f1: 0.637\n",
      "[229, 140.3] loss: 0.001, acc: 0.508, f1: 0.634\n",
      "[230, 139.8] loss: 0.001, acc: 0.520, f1: 0.644\n",
      "[231, 139.7] loss: 0.001, acc: 0.520, f1: 0.645\n",
      "[232, 140.0] loss: 0.001, acc: 0.515, f1: 0.637\n",
      "[233, 139.9] loss: 0.001, acc: 0.530, f1: 0.648\n",
      "[234, 139.7] loss: 0.001, acc: 0.533, f1: 0.649\n",
      "[235, 140.5] loss: 0.001, acc: 0.506, f1: 0.631\n",
      "[236, 139.8] loss: 0.001, acc: 0.511, f1: 0.637\n",
      "[237, 139.7] loss: 0.001, acc: 0.505, f1: 0.648\n",
      "[238, 139.9] loss: 0.002, acc: 0.503, f1: 0.624\n",
      "[239, 139.9] loss: 0.001, acc: 0.522, f1: 0.630\n",
      "[240, 140.3] loss: 0.002, acc: 0.528, f1: 0.646\n",
      "[241, 389.0] loss: 0.001, acc: 0.527, f1: 0.646\n",
      "[242, 139.6] loss: 0.001, acc: 0.505, f1: 0.605\n",
      "[243, 139.4] loss: 0.001, acc: 0.541, f1: 0.643\n",
      "[244, 139.9] loss: 0.001, acc: 0.519, f1: 0.635\n",
      "[245, 139.3] loss: 0.001, acc: 0.498, f1: 0.614\n",
      "[246, 139.8] loss: 0.001, acc: 0.472, f1: 0.588\n",
      "[247, 139.6] loss: 0.001, acc: 0.507, f1: 0.628\n",
      "[248, 140.3] loss: 0.001, acc: 0.520, f1: 0.637\n",
      "[249, 140.3] loss: 0.001, acc: 0.467, f1: 0.611\n",
      "[250, 140.1] loss: 0.001, acc: 0.484, f1: 0.616\n",
      "[251, 139.7] loss: 0.001, acc: 0.510, f1: 0.637\n",
      "[252, 141.5] loss: 0.001, acc: 0.511, f1: 0.621\n",
      "[253, 140.1] loss: 0.001, acc: 0.505, f1: 0.616\n",
      "[254, 140.8] loss: 0.001, acc: 0.530, f1: 0.643\n",
      "[255, 140.2] loss: 0.001, acc: 0.538, f1: 0.646\n",
      "[256, 140.4] loss: 0.001, acc: 0.513, f1: 0.628\n",
      "[257, 141.8] loss: 0.002, acc: 0.522, f1: 0.621\n",
      "[258, 139.9] loss: 0.001, acc: 0.542, f1: 0.648\n",
      "[259, 141.6] loss: 0.001, acc: 0.515, f1: 0.632\n",
      "[260, 140.6] loss: 0.001, acc: 0.530, f1: 0.627\n",
      "[261, 387.3] loss: 0.001, acc: 0.542, f1: 0.647\n",
      "[262, 140.6] loss: 0.001, acc: 0.525, f1: 0.644\n",
      "[263, 140.4] loss: 0.001, acc: 0.555, f1: 0.659\n",
      "[264, 141.5] loss: 0.001, acc: 0.511, f1: 0.621\n",
      "[265, 140.4] loss: 0.001, acc: 0.514, f1: 0.608\n",
      "[266, 141.7] loss: 0.001, acc: 0.514, f1: 0.626\n",
      "[267, 141.1] loss: 0.001, acc: 0.523, f1: 0.632\n",
      "[268, 141.7] loss: 0.001, acc: 0.492, f1: 0.602\n",
      "[269, 140.1] loss: 0.001, acc: 0.511, f1: 0.614\n",
      "[270, 140.9] loss: 0.001, acc: 0.520, f1: 0.622\n",
      "[271, 141.4] loss: 0.001, acc: 0.535, f1: 0.639\n",
      "[272, 140.6] loss: 0.001, acc: 0.481, f1: 0.603\n",
      "[273, 140.2] loss: 0.001, acc: 0.539, f1: 0.646\n",
      "[274, 140.1] loss: 0.001, acc: 0.542, f1: 0.637\n",
      "[275, 140.5] loss: 0.001, acc: 0.527, f1: 0.622\n",
      "[276, 140.6] loss: 0.001, acc: 0.533, f1: 0.642\n",
      "[277, 141.8] loss: 0.001, acc: 0.480, f1: 0.581\n",
      "[278, 141.0] loss: 0.001, acc: 0.521, f1: 0.627\n",
      "[279, 139.9] loss: 0.001, acc: 0.502, f1: 0.603\n",
      "[280, 140.9] loss: 0.001, acc: 0.527, f1: 0.622\n",
      "[281, 384.4] loss: 0.001, acc: 0.558, f1: 0.638\n",
      "[282, 141.1] loss: 0.001, acc: 0.561, f1: 0.646\n",
      "[283, 141.1] loss: 0.001, acc: 0.519, f1: 0.631\n",
      "[284, 140.0] loss: 0.001, acc: 0.523, f1: 0.636\n",
      "[285, 141.3] loss: 0.001, acc: 0.517, f1: 0.616\n",
      "[286, 141.5] loss: 0.001, acc: 0.525, f1: 0.623\n",
      "[287, 141.8] loss: 0.001, acc: 0.529, f1: 0.619\n",
      "[288, 141.2] loss: 0.001, acc: 0.555, f1: 0.651\n",
      "[289, 140.4] loss: 0.001, acc: 0.538, f1: 0.640\n",
      "[290, 141.0] loss: 0.001, acc: 0.511, f1: 0.617\n",
      "[291, 140.4] loss: 0.001, acc: 0.521, f1: 0.631\n",
      "[292, 139.6] loss: 0.001, acc: 0.530, f1: 0.639\n",
      "[293, 140.5] loss: 0.001, acc: 0.532, f1: 0.634\n",
      "[294, 140.6] loss: 0.001, acc: 0.513, f1: 0.627\n",
      "[295, 140.4] loss: 0.001, acc: 0.519, f1: 0.634\n",
      "[296, 140.6] loss: 0.001, acc: 0.543, f1: 0.647\n",
      "[297, 140.6] loss: 0.001, acc: 0.517, f1: 0.622\n",
      "[298, 140.5] loss: 0.001, acc: 0.501, f1: 0.610\n",
      "[299, 142.3] loss: 0.001, acc: 0.508, f1: 0.604\n",
      "[300, 141.6] loss: 0.001, acc: 0.538, f1: 0.635\n",
      "[301, 387.7] loss: 0.001, acc: 0.506, f1: 0.614\n",
      "[302, 141.7] loss: 0.001, acc: 0.545, f1: 0.643\n",
      "[303, 159.9] loss: 0.001, acc: 0.545, f1: 0.643\n",
      "[304, 146.1] loss: 0.001, acc: 0.538, f1: 0.646\n",
      "[305, 141.2] loss: 0.001, acc: 0.501, f1: 0.599\n",
      "[306, 142.6] loss: 0.001, acc: 0.502, f1: 0.602\n",
      "[307, 141.9] loss: 0.001, acc: 0.539, f1: 0.642\n",
      "[308, 141.9] loss: 0.001, acc: 0.546, f1: 0.658\n",
      "[309, 141.7] loss: 0.001, acc: 0.522, f1: 0.642\n",
      "[310, 141.4] loss: 0.001, acc: 0.541, f1: 0.652\n",
      "[311, 183.5] loss: 0.001, acc: 0.533, f1: 0.642\n",
      "[312, 179.5] loss: 0.001, acc: 0.532, f1: 0.627\n",
      "[313, 140.7] loss: 0.001, acc: 0.534, f1: 0.636\n",
      "[314, 140.9] loss: 0.001, acc: 0.535, f1: 0.638\n",
      "[315, 141.5] loss: 0.001, acc: 0.535, f1: 0.628\n",
      "[316, 142.7] loss: 0.001, acc: 0.513, f1: 0.617\n",
      "[317, 142.1] loss: 0.001, acc: 0.499, f1: 0.624\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(330):\n",
    "    t0 = time.time()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        model.train()\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % len(train_dl) == len(train_dl)-1:\n",
    "            model.eval();\n",
    "            preds = []\n",
    "            targs = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data in valid_dl:\n",
    "                    inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                    outputs = model(inputs)\n",
    "                    preds.append(outputs.cpu().detach())\n",
    "                    targs.append(labels.cpu().detach())\n",
    "\n",
    "                preds = torch.cat(preds)\n",
    "                targs = torch.cat(targs)\n",
    "            \n",
    "            accuracy = accuracy_score(preds.sigmoid() > 0.5, targs)\n",
    "            f1 = f1_score(preds.sigmoid() > 0.5, targs, average='micro')\n",
    "            print(f'[{epoch + 1}, {time.time() - t0:.1f}] loss: {running_loss / (len(train_dl)-1):.3f}, acc: {accuracy:.3f}, f1: {f1:.3f}')\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        if (epoch % 20 == 0) and (epoch != 0): torch.save(model.state_dict(), f'models/{epoch}_{round(f1, 2)}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'models/{epoch}_{round(f1, 2)}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
