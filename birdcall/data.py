# AUTOGENERATED! DO NOT EDIT! File to edit: 01_getting_started.ipynb (unless otherwise specified).

__all__ = ['NUM_WORKERS', 'SAMPLE_RATE', 'get_items', 'trn_val_split_items', 'calculate_mean_and_std', 'AudioDataset']

# Cell

import soundfile as sf
from pathlib import Path
import librosa
import numpy as np
from multiprocessing import Pool, cpu_count
import pandas as pd

import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# Cell
NUM_WORKERS = cpu_count()
SAMPLE_RATE = 48_000

# Cell

def get_items(n_per_class=1000):
    len_df = pd.read_pickle('data/ebird_path_duration.pkl')
    items = []

    for idx, species in len_df.iterrows():
        begin_offsets = [5*i for i in range(int(species.duration // 5))]

        examples = [(species.path.stem, species.path, o) for o in begin_offsets]

        if len(examples) < n_per_class:
            examples = examples * (n_per_class // len(examples) + 1)
        else:
            np.random.shuffle(examples)
        items += examples[:n_per_class]

    classes = [itm[0] for itm in items]

    return np.array(items), np.unique(classes).tolist()

# Cell

from sklearn.model_selection import StratifiedKFold

def trn_val_split_items(items, n_splits=5):
    sk_fold = StratifiedKFold(n_splits=n_splits, shuffle=True)
    return list(sk_fold.split(items[:, 0], items[:, 0]))

# Cell

from torch.utils.data import Dataset

def calculate_mean_and_std(items, trn_idxs):
    trn_items = items[trn_idxs][:]
    np.random.shuffle(trn_items)
    examples = np.stack([sf.read(path, frames=5*SAMPLE_RATE, start=offset)[0] for _, path, offset in trn_items[:200]])
    return examples.mean(), examples.std()

class AudioDataset(Dataset):
    def __init__(self, items, classes, mean=None, std=None):
        self.items = items
        self.vocab = classes
        self.do_norm = (mean and std)
        self.mean = mean
        self.std = std
    def __getitem__(self, idx):
        cls, path, offset = self.items[idx]
        x, _ = sf.read(path, SAMPLE_RATE*5, start=offset)
        if self.do_norm: x = self.normalize(x)
        y = self.vocab.index(cls)
        return x.astype(np.float32), self.one_hot_encode(y)
    def normalize(self, x):
        return (x - self.mean) / self.std
    def one_hot_encode(self, y):
        one_hot = np.zeros((len(self.vocab)))
        one_hot[y] = 1
        return one_hot
    def __len__(self):
        return len(self.items)