# AUTOGENERATED! DO NOT EDIT! File to edit: 01_getting_started.ipynb (unless otherwise specified).

__all__ = ['NUM_WORKERS', 'SAMPLE_RATE', 'AudioDataset', 'classes', 'train_ds', 'valid_ds', 'audio_to_spec',
           'SpectrogramDataset']

# Cell

import soundfile as sf
from pathlib import Path
import librosa
import numpy as np
from multiprocessing import Pool, cpu_count
import pandas as pd

import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# Cell
NUM_WORKERS = cpu_count()
SAMPLE_RATE = 32_000

# Cell

from torch.utils.data import Dataset

class AudioDataset(Dataset):
    def __init__(self, recs, classes, len_mult=20, mean=None, std=None):
        self.recs = recs
        self.vocab = classes
        self.do_norm = (mean and std)
        self.mean = mean
        self.std = std
        self.len_mult = len_mult
    def __getitem__(self, idx):
        cls_idx = idx % len(self.vocab)
        recs = self.recs[classes[cls_idx]]
        path, duration = recs[np.random.randint(0, len(recs))]
        if duration > 5:
            x, _ = sf.read(path, start=int(np.random.rand() * (duration-5) * SAMPLE_RATE), frames=5*SAMPLE_RATE)
#             x, _ = librosa.load(path, sr=None, duration=5, offset=np.random.rand() * (duration-5))
        else:
            # this branch of the if condition is slow - I suspect due to np.tile? might want to
            # revisit what we do here down the road, also - it would probably be better to not repeat the signal
            # but rather embed it in some appropriate and longer environment sound
            # on the other hand this branch is not triggered very often so that maybe is not that big of a problem
            x, _ = sf.read(path)
#             x, _ = librosa.load(path, sr=None)
            x =  np.tile(x, 15) # the shortest rec in the train set is 0.39 sec
            start_frame = int(np.random.rand() * (x.shape[0] - 5 * SAMPLE_RATE))
            x = x[start_frame:start_frame+5*SAMPLE_RATE]
        if x.shape[0] != 5 * SAMPLE_RATE: raise Exception(f'Incorrect length: {x.shape[0]}, {path}, {duration}')
        if self.do_norm: x = self.normalize(x)
        return x.astype(np.float32), self.one_hot_encode(cls_idx)
    def normalize(self, x):
        return (x - self.mean) / self.std
    def one_hot_encode(self, y):
        one_hot = np.zeros((len(self.vocab)))
        one_hot[y] = 1
        return one_hot
    def __len__(self):
        return self.len_mult * len(self.vocab)

# Cell
classes = pd.read_pickle('data/classes.pkl')
train_ds = AudioDataset(pd.read_pickle('data/train_set.pkl'), classes, mean=1.6537946e-05, std=0.04572224)
valid_ds = AudioDataset(pd.read_pickle('data/val_set.pkl'), classes, len_mult=10, mean=1.6537946e-05, std=0.04572224)

# Comes from 01a_spectrogram_dataset.ipynb, cell
def audio_to_spec(audio):
    spec = librosa.power_to_db(
        librosa.feature.melspectrogram(audio, sr=SAMPLE_RATE, fmin=20, fmax=16000, n_mels=128)
#         librosa.feature.melspectrogram(audio, sr=SAMPLE_RATE, hop_length=1255, fmin=20, fmax=16000)
    )
    return spec

# Comes from 01a_spectrogram_dataset.ipynb, cell

import matplotlib.pyplot as plt

class SpectrogramDataset(Dataset):
    def __init__(self, recs, classes, len_mult=20, spec_min=None, spec_max=None):
        self.recs = recs
        self.vocab = classes
        self.do_norm = (spec_min and spec_max)
        self.spec_min = spec_min
        self.spec_max = spec_max
        self.len_mult = len_mult
    def __getitem__(self, idx):
        cls_idx = idx % len(self.vocab)
        recs = self.recs[classes[cls_idx]]
        path, duration = recs[np.random.randint(0, len(recs))]
        if duration > 5:
            x, _ = sf.read(path, start=int(np.random.rand() * (duration-5) * SAMPLE_RATE), frames=5*SAMPLE_RATE)
        else:
            x, _ = sf.read(path)
            x =  np.tile(x, 15) # the shortest rec in the train set is 0.39 sec
            start_frame = int(np.random.rand() * (x.shape[0] - 5 * SAMPLE_RATE))
            x = x[start_frame:start_frame+5*SAMPLE_RATE]
        if x.shape[0] != 5 * SAMPLE_RATE: raise Exception(f'Incorrect length: {x.shape[0]}, {path}, {duration}')
        x = audio_to_spec(x)
        if self.do_norm: x = self.normalize(x)
        img = np.repeat(x[None, :, :], 3, 0)

        return img.astype(np.float32), self.one_hot_encode(cls_idx)
    def normalize(self, x):
        x = (x - self.spec_min) / (self.spec_max - self.spec_min)
        return (x - 0.36829123) / 0.08813263

    def show(self, idx):
        x = self[idx][0]
        x = (x * 0.36829123) + 0.08813263
        return plt.imshow(x.transpose(1,2,0)[:, :, 0])

    def one_hot_encode(self, y):
        one_hot = np.zeros((len(self.vocab)))
        one_hot[y] = 1
        return one_hot
    def __len__(self):
        return self.len_mult * len(self.vocab)