# AUTOGENERATED! DO NOT EDIT! File to edit: 01_getting_started.ipynb (unless otherwise specified).

__all__ = ['NUM_WORKERS', 'SAMPLE_RATE', 'AudioDataset', 'classes', 'train_ds', 'valid_ds', 'audio_to_spec',
           'SpectrogramDataset', 'mel_bands', 'mel_min', 'mel_max', 'spectrogram', 'create_mel_filterbank',
           'spectrogram_plans', 'audio_to_melspec', 'MelspecPoolDataset']

# Cell

import soundfile as sf
from pathlib import Path
import librosa
import numpy as np
from multiprocessing import Pool, cpu_count
import pandas as pd

import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# Cell
NUM_WORKERS = cpu_count()
SAMPLE_RATE = 32_000

# Cell

from torch.utils.data import Dataset

class AudioDataset(Dataset):
    def __init__(self, recs, classes, len_mult=20, mean=None, std=None):
        self.recs = recs
        self.vocab = classes
        self.do_norm = (mean and std)
        self.mean = mean
        self.std = std
        self.len_mult = len_mult
    def __getitem__(self, idx):
        cls_idx = idx % len(self.vocab)
        recs = self.recs[classes[cls_idx]]
        path, duration = recs[np.random.randint(0, len(recs))]
        if duration > 5:
            x, _ = sf.read(path, start=int(np.random.rand() * (duration-5) * SAMPLE_RATE), frames=5*SAMPLE_RATE)
#             x, _ = librosa.load(path, sr=None, duration=5, offset=np.random.rand() * (duration-5))
        else:
            # this branch of the if condition is slow - I suspect due to np.tile? might want to
            # revisit what we do here down the road, also - it would probably be better to not repeat the signal
            # but rather embed it in some appropriate and longer environment sound
            # on the other hand this branch is not triggered very often so that maybe is not that big of a problem
            x, _ = sf.read(path)
#             x, _ = librosa.load(path, sr=None)
            x =  np.tile(x, 15) # the shortest rec in the train set is 0.39 sec
            start_frame = int(np.random.rand() * (x.shape[0] - 5 * SAMPLE_RATE))
            x = x[start_frame:start_frame+5*SAMPLE_RATE]
        if x.shape[0] != 5 * SAMPLE_RATE: raise Exception(f'Incorrect length: {x.shape[0]}, {path}, {duration}')
        if self.do_norm: x = self.normalize(x)
        return x.astype(np.float32), self.one_hot_encode(cls_idx)
    def normalize(self, x):
        return (x - self.mean) / self.std
    def one_hot_encode(self, y):
        one_hot = np.zeros((len(self.vocab)))
        one_hot[y] = 1
        return one_hot
    def __len__(self):
        return self.len_mult * len(self.vocab)

# Cell
classes = pd.read_pickle('data/classes.pkl')
train_ds = AudioDataset(pd.read_pickle('data/train_set.pkl'), classes, mean=1.6537946e-05, std=0.04572224)
valid_ds = AudioDataset(pd.read_pickle('data/val_set.pkl'), classes, len_mult=10, mean=1.6537946e-05, std=0.04572224)

# Comes from 01a_spectrogram_dataset.ipynb, cell

import scipy

def audio_to_spec(audio):
    f, t, spec = scipy.signal.spectrogram(audio, fs=SAMPLE_RATE)#, nperseg=360)
    spec = np.log10(spec.clip(1e-10))
    return spec[10:100]
    spec = librosa.power_to_db(
#         librosa.feature.melspectrogram(audio, sr=SAMPLE_RATE, fmin=20, fmax=16000, n_mels=224, hop_length=360)
        librosa.feature.melspectrogram(audio, sr=SAMPLE_RATE, fmin=20, fmax=16000, n_mels=128)
#         librosa.feature.melspectrogram(audio, sr=SAMPLE_RATE, hop_length=1255, fmin=20, fmax=16000)
    )
    return spec

# Comes from 01a_spectrogram_dataset.ipynb, cell

import matplotlib.pyplot as plt

class SpectrogramDataset(Dataset):
    def __init__(self, recs, classes, len_mult=20, spec_min=None, spec_max=None):
        self.recs = recs
        self.vocab = classes
        self.do_norm = (spec_min and spec_max)
        self.spec_min = spec_min
        self.spec_max = spec_max
        self.len_mult = len_mult
    def __getitem__(self, idx):
        cls_idx = idx % len(self.vocab)
        recs = self.recs[classes[cls_idx]]
        path, duration = recs[np.random.randint(0, len(recs))]
        if duration > 5:
            x, _ = sf.read(path, start=int(np.random.rand() * (duration-5) * SAMPLE_RATE), frames=5*SAMPLE_RATE)
        else:
            x, _ = sf.read(path)
            x =  np.tile(x, 15) # the shortest rec in the train set is 0.39 sec
            start_frame = int(np.random.rand() * (x.shape[0] - 5 * SAMPLE_RATE))
            x = x[start_frame:start_frame+5*SAMPLE_RATE]
        if x.shape[0] != 5 * SAMPLE_RATE: raise Exception(f'Incorrect length: {x.shape[0]}, {path}, {duration}')
        x = audio_to_spec(x)
        if self.do_norm: x = self.normalize(x)
        img = np.repeat(x[None, :, :], 3, 0)

        return img.astype(np.float32), self.one_hot_encode(cls_idx)
    def normalize(self, x):
        return ((x - x.min()) / (x.max() - x.min() + 1e-8) - 0.11754986) / 0.16654329
        x = (x - self.spec_min) / (self.spec_max - self.spec_min)
        return (x - 0.36829123) / 0.08813263

    def show(self, idx):
        x = self[idx][0]
        x = (x * 0.36829123) + 0.08813263
        return plt.imshow(x.transpose(1,2,0)[:, :, 0])

    def one_hot_encode(self, y):
        one_hot = np.zeros((len(self.vocab)))
        one_hot[y] = 1
        return one_hot
    def __len__(self):
        return self.len_mult * len(self.vocab)

# Comes from 01b_melspectrogram_dataset_for_pool.ipynb, cell

from pyfftw.builders import rfft as rfft_builder
from pyfftw import empty_aligned

mel_bands=80
mel_min=27.5
mel_max=10000

# Comes from 01b_melspectrogram_dataset_for_pool.ipynb, cell

def spectrogram(samples, sample_rate, frame_len, fps, batch=48, dtype=None,
                bins=None, plans=None):
    """
    Computes a magnitude spectrogram for a given vector of samples at a given
    sample rate (in Hz), frame length (in samples) and frame rate (in Hz).
    Allows to transform multiple frames at once for improved performance (with
    a default value of 48, more is not always better). Returns a numpy array.
    Allows to return a limited number of bins only, with improved performance
    over discarding them afterwards. Optionally accepts a set of precomputed
    plans created with spectrogram_plans(), required when multi-threading.
    """
    if dtype is None:
        dtype = samples.dtype
    if bins is None:
        bins = frame_len // 2 + 1
    if len(samples) < frame_len:
        return np.empty((0, bins), dtype=dtype)
    if plans is None:
        plans = spectrogram_plans(frame_len, batch, dtype)
    rfft1, rfft, win = plans
    hopsize = int(sample_rate // fps)
    num_frames = (len(samples) - frame_len) // hopsize + 1
    nabs = np.abs
    naa = np.asanyarray
    if batch > 1 and num_frames >= batch and samples.flags.c_contiguous:
        frames = np.lib.stride_tricks.as_strided(
                samples, shape=(num_frames, frame_len),
                strides=(samples.strides[0] * hopsize, samples.strides[0]))
        spect = [nabs(rfft(naa(frames[pos:pos + batch:], dtype) * win)[:, :bins])
                 for pos in range(0, num_frames - batch + 1, batch)]
        samples = samples[(num_frames // batch * batch) * hopsize::]
        num_frames = num_frames % batch
    else:
        spect = []
    if num_frames:
        spect.append(np.vstack(
                [nabs(rfft1(naa(samples[pos:pos + frame_len:],
                                dtype) * win)[:bins:])
                 for pos in range(0, len(samples) - frame_len + 1, hopsize)]))
    return np.vstack(spect) if len(spect) > 1 else spect[0]


def create_mel_filterbank(sample_rate, frame_len, num_bands, min_freq,
                          max_freq):
    """
    Creates a mel filterbank of `num_bands` triangular filters, with the first
    filter starting at `min_freq` and the last one stopping at `max_freq`.
    Returns the filterbank as a matrix suitable for a dot product against
    magnitude spectra created from samples at a sample rate of `sample_rate`
    with a window length of `frame_len` samples.
    """
    # prepare output matrix
    input_bins = (frame_len // 2) + 1
    filterbank = np.zeros((input_bins, num_bands))

    # mel-spaced peak frequencies
    min_mel = 1127 * np.log1p(min_freq / 700.0)
    max_mel = 1127 * np.log1p(max_freq / 700.0)
    spacing = (max_mel - min_mel) / (num_bands + 1)
    peaks_mel = min_mel + np.arange(num_bands + 2) * spacing
    peaks_hz = 700 * (np.exp(peaks_mel / 1127) - 1)
    fft_freqs = np.linspace(0, sample_rate / 2., input_bins)
    peaks_bin = np.searchsorted(fft_freqs, peaks_hz)

    # fill output matrix with triangular filters
    for b, filt in enumerate(filterbank.T):
        # The triangle starts at the previous filter's peak (peaks_freq[b]),
        # has its maximum at peaks_freq[b+1] and ends at peaks_freq[b+2].
        left_hz, top_hz, right_hz = peaks_hz[b:b + 3]  # b, b+1, b+2
        left_bin, top_bin, right_bin = peaks_bin[b:b + 3]
        # Create triangular filter compatible to yaafe
        filt[left_bin:top_bin] = ((fft_freqs[left_bin:top_bin] - left_hz) /
                                  (top_bin - left_bin))
        filt[top_bin:right_bin] = ((right_hz - fft_freqs[top_bin:right_bin]) /
                                   (right_bin - top_bin))
        filt[left_bin:right_bin] /= filt[left_bin:right_bin].sum()

    return filterbank

def spectrogram_plans(frame_len, batch=48, dtype=np.float32):
    """
    Precompute plans for spectrogram(), for a given frame length, batch size
    and dtype. Returns two plans (single spectrum and batch), and a window.
    """
    input_array = empty_aligned((batch, frame_len), dtype=dtype)
    win = np.hanning(frame_len).astype(dtype)
    return (rfft_builder(input_array[0]), rfft_builder(input_array), win)

# Comes from 01b_melspectrogram_dataset_for_pool.ipynb, cell

def audio_to_melspec(audio):
    spec = spectrogram(audio, SAMPLE_RATE, 256, 128)
    filterbank = create_mel_filterbank(SAMPLE_RATE, 256, mel_bands, mel_min, mel_max)
    return (spec @ filterbank).T

# Comes from 01b_melspectrogram_dataset_for_pool.ipynb, cell

class MelspecPoolDataset(Dataset):
    def __init__(self, recs, classes, len_mult=20, specs_per_example=30):
        self.recs = recs
        self.vocab = classes
        self.specs_per_example = specs_per_example
        self.len_mult = len_mult

    def __getitem__(self, idx):
        cls_idx = idx % len(self.vocab)
        recs = self.recs[classes[cls_idx]]
        path, duration = recs[np.random.randint(0, len(recs))]
        example = self.sample_specs(path, duration, self.specs_per_example)
        example = self.normalize(example)
        imgs = example.reshape(-1, 3, 80, 212)
        return imgs.astype(np.float32), self.one_hot_encode(cls_idx)

    def sample_specs(self, path, duration, count):
        x, _ = sf.read(path)

        if x.shape[0] < 1.66*SAMPLE_RATE:
            x =  np.tile(x, 5) # the shortest rec in the train set is 0.39 sec

        xs = []
        for _ in range(count):
            start_frame = int(np.random.rand() * (x.shape[0] - 1.66 * SAMPLE_RATE))
            xs.append(x[start_frame:start_frame+int(1.66*SAMPLE_RATE)])

        specs = []
        for x in xs:
            specs.append(audio_to_melspec(x))
        return np.stack(specs)

    def normalize(self, example):
        return (example - 0.12934518) / 0.5612393

    def show(self, idx):
        x = self[idx][0][0]
        return plt.imshow(x.transpose(1,2,0)[:, :, 0])

    def one_hot_encode(self, y):
        one_hot = np.zeros((len(self.vocab)))
        one_hot[y] = 1
        return one_hot
    def __len__(self):
        return self.len_mult * len(self.vocab)