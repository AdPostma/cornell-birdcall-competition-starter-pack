# AUTOGENERATED! DO NOT EDIT! File to edit: 01_getting_started.ipynb (unless otherwise specified).

__all__ = ['NUM_WORKERS', 'SAMPLE_RATE', 'AudioDataset', 'classes', 'train_ds', 'valid_ds', 'audio_to_spec',
           'SpectrogramDataset', 'mel_bands', 'mel_min', 'mel_max', 'spectrogram', 'create_mel_filterbank',
           'spectrogram_plans', 'audio_to_melspec', 'MelspecPoolDataset', 'audio_to_melspec', 'filterbank',
           'create_example', 'bin_items', 'MelspecShortishDataset', 'batch_sampler', 'BatchSampler',
           'MelspecShortishValidatioDataset', 'translate_class', 'MelspecPoolDatasetNegativeClass',
           'MelspecShortishValidatioDataset', 'bin_items_negative_class']

# Cell

import soundfile as sf
from pathlib import Path
import librosa
import numpy as np
from multiprocessing import Pool, cpu_count
import pandas as pd

import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# Cell
NUM_WORKERS = cpu_count()
SAMPLE_RATE = 32_000

# Cell

from torch.utils.data import Dataset

class AudioDataset(Dataset):
    def __init__(self, recs, classes, len_mult=20, mean=None, std=None):
        self.recs = recs
        self.vocab = classes
        self.do_norm = (mean and std)
        self.mean = mean
        self.std = std
        self.len_mult = len_mult
    def __getitem__(self, idx):
        cls_idx = idx % len(self.vocab)
        recs = self.recs[classes[cls_idx]]
        path, duration = recs[np.random.randint(0, len(recs))]
        if duration > 5:
            x, _ = sf.read(path, start=int(np.random.rand() * (duration-5) * SAMPLE_RATE), frames=5*SAMPLE_RATE)
#             x, _ = librosa.load(path, sr=None, duration=5, offset=np.random.rand() * (duration-5))
        else:
            # this branch of the if condition is slow - I suspect due to np.tile? might want to
            # revisit what we do here down the road, also - it would probably be better to not repeat the signal
            # but rather embed it in some appropriate and longer environment sound
            # on the other hand this branch is not triggered very often so that maybe is not that big of a problem
            x, _ = sf.read(path)
#             x, _ = librosa.load(path, sr=None)
            x =  np.tile(x, 15) # the shortest rec in the train set is 0.39 sec
            start_frame = int(np.random.rand() * (x.shape[0] - 5 * SAMPLE_RATE))
            x = x[start_frame:start_frame+5*SAMPLE_RATE]
        if x.shape[0] != 5 * SAMPLE_RATE: raise Exception(f'Incorrect length: {x.shape[0]}, {path}, {duration}')
        if self.do_norm: x = self.normalize(x)
        return x.astype(np.float32), self.one_hot_encode(cls_idx)
    def normalize(self, x):
        return (x - self.mean) / self.std
    def one_hot_encode(self, y):
        one_hot = np.zeros((len(self.vocab)))
        one_hot[y] = 1
        return one_hot
    def __len__(self):
        return self.len_mult * len(self.vocab)

# Cell
classes = pd.read_pickle('data/classes.pkl')
train_ds = AudioDataset(pd.read_pickle('data/train_set.pkl'), classes, mean=1.6537946e-05, std=0.04572224)
valid_ds = AudioDataset(pd.read_pickle('data/val_set.pkl'), classes, len_mult=10, mean=1.6537946e-05, std=0.04572224)

# Comes from 01a_spectrogram_dataset.ipynb, cell

import scipy

def audio_to_spec(audio):
    f, t, spec = scipy.signal.spectrogram(audio, fs=SAMPLE_RATE)#, nperseg=360)
    spec = np.log10(spec.clip(1e-10))
    return spec[10:100]
    spec = librosa.power_to_db(
#         librosa.feature.melspectrogram(audio, sr=SAMPLE_RATE, fmin=20, fmax=16000, n_mels=224, hop_length=360)
        librosa.feature.melspectrogram(audio, sr=SAMPLE_RATE, fmin=20, fmax=16000, n_mels=128)
#         librosa.feature.melspectrogram(audio, sr=SAMPLE_RATE, hop_length=1255, fmin=20, fmax=16000)
    )
    return spec

# Comes from 01a_spectrogram_dataset.ipynb, cell

import matplotlib.pyplot as plt

class SpectrogramDataset(Dataset):
    def __init__(self, recs, classes, len_mult=20, spec_min=None, spec_max=None):
        self.recs = recs
        self.vocab = classes
        self.do_norm = (spec_min and spec_max)
        self.spec_min = spec_min
        self.spec_max = spec_max
        self.len_mult = len_mult
    def __getitem__(self, idx):
        cls_idx = idx % len(self.vocab)
        recs = self.recs[classes[cls_idx]]
        path, duration = recs[np.random.randint(0, len(recs))]
        if duration > 5:
            x, _ = sf.read(path, start=int(np.random.rand() * (duration-5) * SAMPLE_RATE), frames=5*SAMPLE_RATE)
        else:
            x, _ = sf.read(path)
            x =  np.tile(x, 15) # the shortest rec in the train set is 0.39 sec
            start_frame = int(np.random.rand() * (x.shape[0] - 5 * SAMPLE_RATE))
            x = x[start_frame:start_frame+5*SAMPLE_RATE]
        if x.shape[0] != 5 * SAMPLE_RATE: raise Exception(f'Incorrect length: {x.shape[0]}, {path}, {duration}')
        x = audio_to_spec(x)
        if self.do_norm: x = self.normalize(x)
        img = np.repeat(x[None, :, :], 3, 0)

        return img.astype(np.float32), self.one_hot_encode(cls_idx)
    def normalize(self, x):
        return ((x - x.min()) / (x.max() - x.min() + 1e-8) - 0.11754986) / 0.16654329
        x = (x - self.spec_min) / (self.spec_max - self.spec_min)
        return (x - 0.36829123) / 0.08813263

    def show(self, idx):
        x = self[idx][0]
        x = (x * 0.36829123) + 0.08813263
        return plt.imshow(x.transpose(1,2,0)[:, :, 0])

    def one_hot_encode(self, y):
        one_hot = np.zeros((len(self.vocab)))
        one_hot[y] = 1
        return one_hot
    def __len__(self):
        return self.len_mult * len(self.vocab)

# Comes from 01b_melspectrogram_dataset_for_pool.ipynb, cell

from pyfftw.builders import rfft as rfft_builder
from pyfftw import empty_aligned

mel_bands=80
mel_min=27.5
mel_max=10000

# Comes from 01b_melspectrogram_dataset_for_pool.ipynb, cell

def spectrogram(samples, sample_rate, frame_len, fps, batch=48, dtype=None,
                bins=None, plans=None):
    """
    Computes a magnitude spectrogram for a given vector of samples at a given
    sample rate (in Hz), frame length (in samples) and frame rate (in Hz).
    Allows to transform multiple frames at once for improved performance (with
    a default value of 48, more is not always better). Returns a numpy array.
    Allows to return a limited number of bins only, with improved performance
    over discarding them afterwards. Optionally accepts a set of precomputed
    plans created with spectrogram_plans(), required when multi-threading.
    """
    if dtype is None:
        dtype = samples.dtype
    if bins is None:
        bins = frame_len // 2 + 1
    if len(samples) < frame_len:
        return np.empty((0, bins), dtype=dtype)
    if plans is None:
        plans = spectrogram_plans(frame_len, batch, dtype)
    rfft1, rfft, win = plans
    hopsize = int(sample_rate // fps)
    num_frames = (len(samples) - frame_len) // hopsize + 1
    nabs = np.abs
    naa = np.asanyarray
    if batch > 1 and num_frames >= batch and samples.flags.c_contiguous:
        frames = np.lib.stride_tricks.as_strided(
                samples, shape=(num_frames, frame_len),
                strides=(samples.strides[0] * hopsize, samples.strides[0]))
        spect = [nabs(rfft(naa(frames[pos:pos + batch:], dtype) * win)[:, :bins])
                 for pos in range(0, num_frames - batch + 1, batch)]
        samples = samples[(num_frames // batch * batch) * hopsize::]
        num_frames = num_frames % batch
    else:
        spect = []
    if num_frames:
        spect.append(np.vstack(
                [nabs(rfft1(naa(samples[pos:pos + frame_len:],
                                dtype) * win)[:bins:])
                 for pos in range(0, len(samples) - frame_len + 1, hopsize)]))
    return np.vstack(spect) if len(spect) > 1 else spect[0]


def create_mel_filterbank(sample_rate, frame_len, num_bands, min_freq,
                          max_freq):
    """
    Creates a mel filterbank of `num_bands` triangular filters, with the first
    filter starting at `min_freq` and the last one stopping at `max_freq`.
    Returns the filterbank as a matrix suitable for a dot product against
    magnitude spectra created from samples at a sample rate of `sample_rate`
    with a window length of `frame_len` samples.
    """
    # prepare output matrix
    input_bins = (frame_len // 2) + 1
    filterbank = np.zeros((input_bins, num_bands))

    # mel-spaced peak frequencies
    min_mel = 1127 * np.log1p(min_freq / 700.0)
    max_mel = 1127 * np.log1p(max_freq / 700.0)
    spacing = (max_mel - min_mel) / (num_bands + 1)
    peaks_mel = min_mel + np.arange(num_bands + 2) * spacing
    peaks_hz = 700 * (np.exp(peaks_mel / 1127) - 1)
    fft_freqs = np.linspace(0, sample_rate / 2., input_bins)
    peaks_bin = np.searchsorted(fft_freqs, peaks_hz)

    # fill output matrix with triangular filters
    for b, filt in enumerate(filterbank.T):
        # The triangle starts at the previous filter's peak (peaks_freq[b]),
        # has its maximum at peaks_freq[b+1] and ends at peaks_freq[b+2].
        left_hz, top_hz, right_hz = peaks_hz[b:b + 3]  # b, b+1, b+2
        left_bin, top_bin, right_bin = peaks_bin[b:b + 3]
        # Create triangular filter compatible to yaafe
        filt[left_bin:top_bin] = ((fft_freqs[left_bin:top_bin] - left_hz) /
                                  (top_bin - left_bin))
        filt[top_bin:right_bin] = ((right_hz - fft_freqs[top_bin:right_bin]) /
                                   (right_bin - top_bin))
        filt[left_bin:right_bin] /= filt[left_bin:right_bin].sum()

    return filterbank

def spectrogram_plans(frame_len, batch=48, dtype=np.float32):
    """
    Precompute plans for spectrogram(), for a given frame length, batch size
    and dtype. Returns two plans (single spectrum and batch), and a window.
    """
    input_array = empty_aligned((batch, frame_len), dtype=dtype)
    win = np.hanning(frame_len).astype(dtype)
    return (rfft_builder(input_array[0]), rfft_builder(input_array), win)

# Comes from 01b_melspectrogram_dataset_for_pool.ipynb, cell

def audio_to_melspec(audio):
    spec = spectrogram(audio, SAMPLE_RATE, 256, 128)
    filterbank = create_mel_filterbank(SAMPLE_RATE, 256, mel_bands, mel_min, mel_max)
    return (spec @ filterbank).T

# Comes from 01b_melspectrogram_dataset_for_pool.ipynb, cell

class MelspecPoolDataset(Dataset):
    def __init__(self, recs, classes, len_mult=20, specs_per_example=30, normalize=True):
        self.recs = recs
        self.vocab = classes
        self.specs_per_example = specs_per_example
        self.len_mult = len_mult
        self.do_norm = normalize

    def __getitem__(self, idx):
        cls_idx = idx % len(self.vocab)
        recs = self.recs[classes[cls_idx]]
        path, duration = recs[np.random.randint(0, len(recs))]
        example = self.sample_specs(path, duration, self.specs_per_example)
        if self.do_norm: example = self.normalize(example)
        imgs = example.reshape(-1, 3, 80, 212)
        return imgs.astype(np.float32), self.one_hot_encode(cls_idx)

    def sample_specs(self, path, duration, count):
        x, _ = sf.read(path)

        if x.shape[0] < 1.66*SAMPLE_RATE:
            x =  np.tile(x, 5) # the shortest rec in the train set is 0.39 sec

        xs = []
        for _ in range(count):
            start_frame = int(np.random.rand() * (x.shape[0] - 1.66 * SAMPLE_RATE))
            xs.append(x[start_frame:start_frame+int(1.66*SAMPLE_RATE)])

        specs = []
        for x in xs:
            specs.append(audio_to_melspec(x))
        return np.stack(specs)

    def normalize(self, example):
        return (example - 0.12934518) / 0.5612393

    def show(self, idx):
        x = self[idx][0][0]
        return plt.imshow(x.transpose(1,2,0)[:, :, 0])

    def one_hot_encode(self, y):
        one_hot = np.zeros((len(self.vocab)))
        one_hot[y] = 1
        return one_hot
    def __len__(self):
        return self.len_mult * len(self.vocab)

# Comes from 01c_melspectrogram_dataset_for_pool_shortish.ipynb, cell

filterbank = create_mel_filterbank(SAMPLE_RATE, 256, mel_bands, mel_min, mel_max)
def audio_to_melspec(audio):
    spec = spectrogram(audio, SAMPLE_RATE, 256, 128)
    return (spec @ filterbank).T

# Comes from 01c_melspectrogram_dataset_for_pool_shortish.ipynb, cell

from collections import defaultdict
from multiprocessing import Pool
import torch

def create_example(item):
    cls_idx, path, num_specs = item
    x, _ = sf.read(path)

    example_duration = num_specs * 5 * SAMPLE_RATE
    if x.shape[0] < example_duration:
        x = np.tile(x, example_duration // x.shape[0] + 1)

    start_frame = np.random.randint(0, x.shape[0] - example_duration+1)
    x = x[start_frame:start_frame+example_duration]

    xs = []
    for i in range(num_specs):
        for j in range(3):
            start_frame = int((i * 3 + j) * 1.66 * SAMPLE_RATE)
            xs.append(x[start_frame:start_frame+int(1.66*SAMPLE_RATE)])

    specs = []
    for x in xs:
        specs.append(audio_to_melspec(x))
    specs = np.stack(specs)
    imgs = specs.reshape(-1, 3, 80, 212)

    one_hot = np.zeros((264))
    one_hot[cls_idx] = 1

    return imgs.astype(np.float32), one_hot

def bin_items(recs, classes):
    binned_items = defaultdict(list)
    for key in recs.keys():
        for path, duration in recs[key]:
            if duration < 7.5: binned_items[1].append((classes.index(key), path, 1))
            elif duration < 12.5: binned_items[2].append((classes.index(key), path, 2))
            elif duration < 25: binned_items[4].append((classes.index(key), path, 4))
            elif duration < 45: binned_items[6].append((classes.index(key), path, 6))
            else: binned_items[10].append((classes.index(key), path, 10))
    return binned_items

class MelspecShortishDataset(torch.utils.data.Dataset):
    def __init__(self, recs, classes):
        self.recs = recs
        self.classes = classes
        self.binned_items = bin_items(recs, classes)

    def __len__(self): raise(NotImplementedError)

    def __getitem__(self, bin_num):
        item_idx = np.random.randint(0, len(self.binned_items[bin_num]))
        item = self.binned_items[bin_num][item_idx]
        return create_example(item)

def batch_sampler(batch_size=16, len_mult=1):
    for i in range(len_mult * 264 // batch_size):
        chosen_bin = np.random.choice([1,2,4,6,10], p=[0.1, 0.225, 0.225, 0.225, 0.225])
        yield [chosen_bin] * batch_size

class BatchSampler():
    def __init__(self, batch_size=16, len_mult=1):
        self.batch_size = batch_size
        self.len_mult = len_mult

    def __iter__(self):
        return batch_sampler(self.batch_size, self.len_mult)

    def __len__(self):
        return self.len_mult * 264 // self.batch_size

# Comes from 01c_melspectrogram_dataset_for_pool_shortish.ipynb, cell

class MelspecShortishValidatioDataset(torch.utils.data.Dataset):
    def __init__(self, items, classes):
        self.classes = classes
        self.items = items

    def __len__(self): return len(self.items)

    def __getitem__(self, idx):
        return self.create_example(self.items[idx])

    def create_example(self, item):
        cls_idx, path, num_specs = item
        x, _ = sf.read(path)

        example_duration = num_specs * 5 * SAMPLE_RATE
        if x.shape[0] < example_duration:
            x = np.tile(x, example_duration // x.shape[0] + 1)

        start_frame = 0
        x = x[start_frame:example_duration]

        xs = []
        for i in range(num_specs):
            for j in range(3):
                start_frame = int((i * 3 + j) * 1.66 * SAMPLE_RATE)
                xs.append(x[start_frame:start_frame+int(1.66*SAMPLE_RATE)])

        specs = []
        for x in xs:
            specs.append(audio_to_melspec(x))
        specs = np.stack(specs)
        imgs = specs.reshape(-1, 3, 80, 212)

        one_hot = np.zeros((264))
        one_hot[cls_idx] = 1

        return imgs.astype(np.float32), one_hot

# Comes from 02ia_train_on_melspectrograms_pytorch_lme_pool_frontend_negative_class_refactored.ipynb, cell
from collections import defaultdict

def translate_class(items, old_vocab, new_vocab):
    items_with_translated_class = []
    for cls_idx, path, duration in items:
        items_with_translated_class.append((new_vocab.index(old_vocab[cls_idx]), path, duration))
    return items_with_translated_class

class MelspecPoolDatasetNegativeClass(torch.utils.data.Dataset):
    def __init__(self, items, items_neg_class, north_american_birds_common, len_mult=20, specs_per_example=30, reshape_to_3ch=True, spec_dur=1.66):
        self.cls_idx_to_recs = defaultdict(list)
        for item in items:
            self.cls_idx_to_recs[item[0]].append(item)
        self.items = items
        self.items_neg_class = items_neg_class
        self.all_classes = classes
        self.vocab = north_american_birds_common
        self.specs_per_example = specs_per_example
        self.len_mult = len_mult
        self.reshape_to_3ch = reshape_to_3ch
        self.spec_dur = spec_dur

    def __getitem__(self, idx):
        if np.random.rand() > 0.54:
            cls_idx = idx % len(self.vocab)
            recs = self.cls_idx_to_recs[cls_idx]
            _, path, duration = recs[np.random.randint(0, len(recs))]
        else:
            cls_idx = -1
            _, path, duration = self.items_neg_class[np.random.randint(len(self.items_neg_class))]

        example = self.sample_specs(path, duration, self.specs_per_example)
        if self.reshape_to_3ch: example = example.reshape(-1, 3, 80, 212)
        return example.astype(np.float32), self.one_hot_encode(cls_idx)

    def sample_specs(self, path, duration, count):
        x, _ = sf.read(path)

        if x.shape[0] < self.spec_dur*SAMPLE_RATE:
            x =  np.tile(x, int(self.spec_dur*SAMPLE_RATE) // x.shape[0] + 1 ) # the shortest rec in the train set is 0.39 sec

        xs = []
        for _ in range(count):
            start_frame = int(np.random.rand() * (x.shape[0] - self.spec_dur * SAMPLE_RATE))
            xs.append(x[start_frame:start_frame+int(self.spec_dur*SAMPLE_RATE)])

        specs = []
        for x in xs:
            specs.append(audio_to_melspec(x))
        return np.stack(specs)

    def show(self, idx):
        x = self[idx][0][0]
        return plt.imshow(x.transpose(1,2,0)[:, :, 0])

    def one_hot_encode(self, y):
        one_hot = np.zeros((len(self.vocab)))
        if y != -1:
            one_hot[y] = 1
        return one_hot

    def __len__(self):
        return self.len_mult * len(self.vocab)

# Comes from 02ia_train_on_melspectrograms_pytorch_lme_pool_frontend_negative_class_refactored.ipynb, cell
class MelspecShortishValidatioDataset(torch.utils.data.Dataset):
    def __init__(self, items, vocab, negative_class_items=[], reshape_to_3ch=True):
        self.vocab = vocab
        self.items = items + negative_class_items
        self.reshape_to_3ch = reshape_to_3ch

    def __len__(self): return len(self.items)

    def __getitem__(self, idx):
        item = self.items[idx]

        return self.create_example(self.items[idx])

    def create_example(self, item):
        cls_idx, path, num_specs = item

        x, _ = sf.read(path)

        example_duration = num_specs * 5 * SAMPLE_RATE
        if x.shape[0] < example_duration:
            x = np.tile(x, example_duration // x.shape[0] + 1)

        start_frame = 0
        x = x[start_frame:example_duration]

        xs = []
        for i in range(num_specs):
            for j in range(3):
                start_frame = int((i * 3 + j) * 1.66 * SAMPLE_RATE)
                xs.append(x[start_frame:start_frame+int(1.66*SAMPLE_RATE)])

        specs = []
        for x in xs:
            specs.append(audio_to_melspec(x))
        specs = np.stack(specs)
        if self.reshape_to_3ch: specs = specs.reshape(-1, 3, 80, 212)

        one_hot = np.zeros((len(self.vocab)))
        if cls_idx != -1: one_hot[cls_idx] = 1

        return specs.astype(np.float32), one_hot

# Comes from 02ia_train_on_melspectrograms_pytorch_lme_pool_frontend_negative_class_refactored.ipynb, cell
def bin_items_negative_class(items):
    binned_items = defaultdict(list)
    for cls_idx, path, duration in items:
        if duration < 7.5: binned_items[1].append((cls_idx, path, 1))
        elif duration < 12.5: binned_items[2].append((cls_idx, path, 2))
        elif duration < 25: binned_items[4].append((cls_idx, path, 4))
        elif duration < 45: binned_items[6].append((cls_idx, path, 6))
        else: binned_items[10].append((cls_idx, path, 10))
    return binned_items